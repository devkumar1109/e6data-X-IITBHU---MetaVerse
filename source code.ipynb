{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please upload the json file and specify the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T12:30:32.461182Z",
     "iopub.status.busy": "2025-09-14T12:30:32.460836Z",
     "iopub.status.idle": "2025-09-14T12:30:32.485872Z",
     "shell.execute_reply": "2025-09-14T12:30:32.481437Z",
     "shell.execute_reply.started": "2025-09-14T12:30:32.461157Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/kaggle/input/test-input/input.json\", \"r\") as file:\n",
    "    input_data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T11:25:25.417528Z",
     "iopub.status.busy": "2025-09-14T11:25:25.417266Z",
     "iopub.status.idle": "2025-09-14T11:25:56.652256Z",
     "shell.execute_reply": "2025-09-14T11:25:56.648292Z",
     "shell.execute_reply.started": "2025-09-14T11:25:25.417505Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv numpy pandas scikit-learn sentence-transformers huggingface-hub hf-xet langchain-groq matplotlib seaborn nltk streamlit transformers -q\n",
    "!pip install langchain langchain-community ipykernel google-search-results json_repair -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T11:26:10.809289Z",
     "iopub.status.busy": "2025-09-14T11:26:10.808986Z",
     "iopub.status.idle": "2025-09-14T11:27:17.187395Z",
     "shell.execute_reply": "2025-09-14T11:27:17.181594Z",
     "shell.execute_reply.started": "2025-09-14T11:26:10.809261Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.10/site-packages/torch_xla/__init__.py:251: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
      "  warnings.warn(\n",
      "WARNING: Logging before InitGoogle() is written to STDERR\n",
      "E0000 00:00:1757849219.394438      10 common_lib.cc:612] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n",
      "=== Source Location Trace: === \n",
      "learning/45eac/tfrc/runtime/common_lib.cc:230\n"
     ]
    }
   ],
   "source": [
    "# import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "from typing import Dict, List\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import json\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import requests\n",
    "import math\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from json_repair import repair_json\n",
    "import json_repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T11:27:17.191725Z",
     "iopub.status.busy": "2025-09-14T11:27:17.191193Z",
     "iopub.status.idle": "2025-09-14T11:27:17.823251Z",
     "shell.execute_reply": "2025-09-14T11:27:17.817660Z",
     "shell.execute_reply.started": "2025-09-14T11:27:17.191699Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T12:00:30.970697Z",
     "iopub.status.busy": "2025-09-14T12:00:30.970382Z",
     "iopub.status.idle": "2025-09-14T12:00:30.982798Z",
     "shell.execute_reply": "2025-09-14T12:00:30.976992Z",
     "shell.execute_reply.started": "2025-09-14T12:00:30.970671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prompts = [input_data['prompt']]\n",
    "agent_responses = [d for d in input_data['agent_responses']]\n",
    "\n",
    "prompts = prompts * len(agent_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T12:00:32.562916Z",
     "iopub.status.busy": "2025-09-14T12:00:32.562597Z",
     "iopub.status.idle": "2025-09-14T12:00:32.610358Z",
     "shell.execute_reply": "2025-09-14T12:00:32.605963Z",
     "shell.execute_reply.started": "2025-09-14T12:00:32.562890Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def my_func(prompt, agent_response, groq_api_key, serpapi_api_key):\n",
    "\n",
    "    def load_semantic_model():\n",
    "        return SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    def load_nli_model():\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "        model_nli = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "        return tokenizer, model_nli\n",
    "\n",
    "    def load_gpt2_for_fluency():\n",
    "        model_for_fluency = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "        tokenizer_for_fluency = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "        model_for_fluency.eval()\n",
    "        return model_for_fluency, tokenizer_for_fluency\n",
    "\n",
    "    def check_factuality(prompt, agent_response, groq_api_key, serpapi_key, max_claims=5, max_results=2):\n",
    "        model = ChatGroq(model='gemma2-9b-it', api_key=groq_api_key)\n",
    "        model2 = ChatGroq(model='llama-3.3-70b-versatile', api_key=groq_api_key)\n",
    "        search = SerpAPIWrapper(serpapi_api_key=serpapi_key, params={\"num\": str(max_results)})\n",
    "\n",
    "        template1 = ChatPromptTemplate([\n",
    "            (\"system\", \"You are a brilliant assistant.\"),\n",
    "            (\"human\", \"\"\"[KB-Based QA]\n",
    "    You are given a piece of text that includes knowledge claims. A claim is a statement that asserts something as true or false, which can be verified by humans.\n",
    "\n",
    "    [Task]\n",
    "    Your task is to accurately identify and extract up to {k} claims stated in the provided text. \n",
    "    Then, resolve any coreference (pronouns or other referring expressions) in the claim for clarity. Each claim should be concise (less than 15 words) and self-contained.\n",
    "    Your response MUST be a list of dictionaries. Each dictionary should contain the key \"claim\", which corresponds to the extracted claim (with all coreferences resolved). \n",
    "    You MUST only respond in the format as described below. DO NOT RESPOND WITH ANYTHING ELSE. ADDING ANY OTHER EXTRA NOTES THAT VIOLATE THE RESPONSE FORMAT IS BANNED. START YOUR RESPONSE WITH '['.\n",
    "    Include **at most {k} claims**. If the text contains fewer than {k} claims, output only the available claims.\n",
    "\n",
    "    [Response Format]\n",
    "    [{{\"claim\": \"Ensure that the claim is fewer than 15 words and conveys a complete idea. Resolve any coreference (pronouns or other referring expressions) in the claim for clarity.\"}}, ... ]\n",
    "\n",
    "    Here are two examples:\n",
    "    [text]:\n",
    "    Tomas Berdych defeated Gael Monfis 6-1, 6-4 on Saturday. The sixth-seed reaches Monte Carlo Masters final for the first time. Berdych will face either Rafael Nadal or Novak Djokovic in the final.\n",
    "    [response]:\n",
    "    [{{\"claim\": \"Tomas Berdych defeated Gael Monfis 6-1, 6-4\"}}, {{\"claim\": \"Tomas Berdych reaches Monte Carlo Masters final\"}}, {{\"claim\": \"Tomas Berdych is the sixth-seed\"}}, {{\"claim\": \"Tomas Berdych will face either Rafael Nadal or Novak Djokovic\"}}, {{\"claim\": \"Berdych will face either Rafael Nadal or Novak Djokovic in the final\"}}]\n",
    "\n",
    "    [text]:\n",
    "    Tinder only displays the last 34 photos - but users can easily see more. Firm also said it had improved its mutual friends feature.\n",
    "    [response]:\n",
    "    [{{\"claim\": \"Tinder only displays the last 34 photos\"}}, {{\"claim\": \"Tinder users can easily see more photos\"}}, {{\"claim\": \"Tinder said it had improved its mutual friends feature\"}}]\n",
    "\n",
    "    Now complete the following:\n",
    "    [text]:\n",
    "    {input_text}\n",
    "    [response]:\n",
    "    \"\"\")\n",
    "        ])\n",
    "\n",
    "        template2 = ChatPromptTemplate([\n",
    "            ('system', \"You are a brilliant assistant.\"),\n",
    "            ('human', \"\"\"[KB-based QA]\n",
    "    You are a query generator designed to help users verify a given claim using search engines. \n",
    "    Your primary task is to generate a **valid JSON array** containing **one effective and skeptical search engine query**. \n",
    "    This query should assist users in critically evaluating the factuality of a provided claim using search engines. \n",
    "\n",
    "    [Important Instructions]\n",
    "    1. You MUST respond **only** in strict JSON format. \n",
    "    2. The JSON array must use **double quotes** for strings, e.g., [\"query here\"].\n",
    "    3. Single quotes (' ') or Python-style lists are invalid and not allowed.\n",
    "    4. Do not include any extra text, comments, or explanations. \n",
    "    5. The array must contain exactly **one query**.\n",
    "    6. Start the response directly with `[` and end with `]`.\n",
    "\n",
    "    [response format]:\n",
    "    [\"query\"]\n",
    "\n",
    "    Here are 3 examples: \n",
    "    [claim]: The CEO of Twitter is Bill Gates. \n",
    "    [response]: [\"Who is the CEO of Twitter?\"]\n",
    "\n",
    "    [claim]: Michael Phelps is the most decorated Olympian of all time. \n",
    "    [response]: [\"Who is the most decorated Olympian of all time?\"]\n",
    "\n",
    "    [claim]: ChatGPT is created by Google. \n",
    "    [response]: [\"Who created ChatGPT?\"]\n",
    "\n",
    "    Now complete the following: \n",
    "    [claim]: {input} \n",
    "    [response]:\n",
    "    \"\"\")\n",
    "        ])\n",
    "        \n",
    "        template3 = ChatPromptTemplate([\n",
    "            ('system', \"You are a brilliant assistant.\"),\n",
    "            ('human', \"\"\"[KB-based QA]\n",
    "You are given a piece of text. Your task is to identify whether there are any factual errors within the text.\n",
    "When you are judging the factuality of the given text, you could reference the provided evidences if needed. \n",
    "The provided evidences may be helpful. Some evidences may contradict to each other. \n",
    "You must be careful when using the evidences to judge the factuality of the given text.\n",
    "The response should be a dictionary with six keys - \"reasoning\", \"factuality\", \"error\", \"out of context\", \"correction\", and \"factually incorrect number of sentence\", which correspond to the reasoning, whether the given text is factual or not (Boolean - True or False), the factual error present in the text, any assumptions or parts that are out of context, the corrected text, and the number of the sentence that are factually incorrect.\n",
    "\n",
    "The following is the given text : {answer} \n",
    "The following is the provided evidences : {evidences} \n",
    "You should only respond in the format as described below. DO NOT RETURN ANYTHING ELSE.\n",
    "START YOUR RESPONSE WITH '{{'. \n",
    "\n",
    "[response format]: \n",
    "{{\"reasoning\": \"Why is the given text factual or non-factual? Be careful when you said something is non-factual. When you said something is non-factual, you must provide multiple evidences to support your decision.\", \n",
    "\"error\": \"None if the text is factual; otherwise, describe the error.\",\n",
    "\"correction\": \"The corrected text if there is an error.\",\n",
    "\"out-of-context\": \"Parts of sentences that were out of context.\",\n",
    "\"factually incorrect number of sentences\": \"A whole number indicating the number of the sentences that are factually incorrect.\",\n",
    "\"factuality\": \"True if the given text is factual, False otherwise.\"}}\n",
    "\"\"\")\n",
    "        ])\n",
    "\n",
    "        prompt1 = template1.invoke({\"input_text\": agent_response, \"k\": str(max_claims)})\n",
    "        result = model.invoke(prompt1)\n",
    "        try:\n",
    "            claims = json_repair.loads(result.content)\n",
    "        except json.JSONDecodeError as e:\n",
    "            return 0.0, {\"error\": \"Failed to parse claims\"}, claims, []\n",
    "            \n",
    "            # st.markdown(\"##### Extracted Claims:\")\n",
    "            # st.json(claims)\n",
    "        \n",
    "        evidences = []\n",
    "        for claim in claims:\n",
    "            try:\n",
    "                prompt2 = template2.invoke({'input': claim['claim']})\n",
    "                response = model.invoke(prompt2)\n",
    "                query = json.loads(response.content.replace(\"\\\\'\", \"'\"))\n",
    "                \n",
    "                res = search.results(query[0])\n",
    "                if \"knowledge_graph\" in res:\n",
    "                    if \"description\" in res['knowledge_graph']:\n",
    "                        evidences.append(res['knowledge_graph']['description'])\n",
    "                \n",
    "                for result_snippet in res.get('organic_results', [])[:max_results]:\n",
    "                    evidences.append(result_snippet['snippet'])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            \n",
    "        try:\n",
    "            prompt3 = template3.invoke({\"answer\": agent_response, \"evidences\": evidences})\n",
    "            result = model2.invoke(prompt3)\n",
    "            \n",
    "            # Clean the response content\n",
    "            content = result.content.strip()\n",
    "\n",
    "            final_evaluation = json_repair.loads(content)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return 0.0, {\"error\": f\"Failed to evaluate factuality: {str(e)}\"}, claims, evidences\n",
    "\n",
    "        try:\n",
    "            total_sentences = len([s for s in agent_response.split('.') if s.strip()])\n",
    "            if total_sentences == 0:\n",
    "                total_sentences = 1\n",
    "            \n",
    "            # incorrect_key = 'factually_incorrect_number_of_sentences'\n",
    "            # if incorrect_key not in final_evaluation:\n",
    "            #     for alt_key in ['factually incorrect number of sentences', 'incorrect_sentences', 'factually_incorrect_sentences']:\n",
    "            #         if alt_key in final_evaluation:\n",
    "            #             incorrect_key = alt_key\n",
    "            #             break\n",
    "            #     else:\n",
    "            #         final_evaluation[incorrect_key] = 0\n",
    "            \n",
    "            incorrect_sentences = int(final_evaluation[\"factually incorrect number of sentences\"])\n",
    "            fact_error = incorrect_sentences / total_sentences\n",
    "            factual_accuracy_score = 1 - fact_error\n",
    "            \n",
    "        except Exception as e:\n",
    "            factual_accuracy_score = 0.0\n",
    "        \n",
    "        return factual_accuracy_score, final_evaluation, claims, evidences\n",
    "\n",
    "    model = load_semantic_model()\n",
    "        \n",
    "    def semantic_score(prompt_hint, response):\n",
    "        emb_pr = model.encode(prompt_hint, convert_to_tensor=True)\n",
    "        emb_res = model.encode(response, convert_to_tensor=True)\n",
    "        sim_score = util.cos_sim(emb_pr, emb_res).item()\n",
    "        return (sim_score + 1) / 2.0\n",
    "\n",
    "    semantic_s = semantic_score(prompt, agent_response)\n",
    "\n",
    "\n",
    "    tokenizer, model_nli = load_nli_model()\n",
    "        \n",
    "    def nli_entailment_prob(premise, hypothesis):\n",
    "        inputs = tokenizer(premise, hypothesis, return_tensors=\"pt\", truncation=True)\n",
    "        logits = model_nli(**inputs).logits\n",
    "        probs = F.softmax(logits, dim=-1)[0].detach().cpu().numpy()\n",
    "        entail_prob = probs[2]\n",
    "        neutral_prob = probs[1]\n",
    "        contradict_prob = probs[0]\n",
    "        return float(entail_prob), float(neutral_prob), float(contradict_prob)\n",
    "\n",
    "    ent, neu, cont = nli_entailment_prob(prompt, agent_response)\n",
    "\n",
    "    # col_nli_1, col_nli_2, col_nli_3 = st.columns(3)\n",
    "    # col_nli_1.metric(\"Entailment\", f\"{ent:.2f}\")\n",
    "    # col_nli_2.metric(\"Neutrality\", f\"{neu:.2f}\")\n",
    "    # col_nli_3.metric(\"Contradiction\", f\"{cont:.2f}\")\n",
    "\n",
    "\n",
    "    def nli_entailment_prob_bw_sentences(premise, hypothesis):\n",
    "        if not premise.strip() or not hypothesis.strip():\n",
    "            return 0.0, 0.0, 0.0\n",
    "        inputs = tokenizer(premise, hypothesis, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        logits = model_nli(**inputs).logits\n",
    "        probs = F.softmax(logits, dim=-1)[0].detach().cpu().numpy()\n",
    "        contradict_prob = probs[0]\n",
    "        neutral_prob = probs[1]\n",
    "        entail_prob = probs[2]\n",
    "        return float(contradict_prob), float(neutral_prob), float(entail_prob) \n",
    "\n",
    "    def sequential_entailment(response):\n",
    "        sentences = nltk.sent_tokenize(response)\n",
    "        sentences = [s.strip() for s in sentences if s.strip()]\n",
    "        \n",
    "        entail_scores = []\n",
    "        neutral_scores = []\n",
    "        contradict_scores = []\n",
    "        \n",
    "        for i in range(len(sentences) - 1):\n",
    "            c, n, e = nli_entailment_prob_bw_sentences(sentences[i], sentences[i+1])\n",
    "            entail_scores.append(e)\n",
    "            neutral_scores.append(n)\n",
    "            contradict_scores.append(c)\n",
    "        \n",
    "        return sentences, entail_scores, neutral_scores, contradict_scores\n",
    "\n",
    "    sentences, entail, neutral, contradict = sequential_entailment(agent_response)\n",
    "\n",
    "    coherent_scores = [0,0,0]\n",
    "    if len(entail) > 0:\n",
    "        overall_neutral_score = sum(neutral) / len(neutral)\n",
    "        overall_entail_score = sum(entail) / len(entail)\n",
    "        overall_contradict_score = sum(contradict) / len(contradict)\n",
    "        coherent_scores = [overall_neutral_score, overall_entail_score, overall_contradict_score]\n",
    "\n",
    "    def lexical_diversity(text):\n",
    "        tokens = nltk.word_tokenize(text.lower())\n",
    "        total = len(tokens)\n",
    "        unique = len(set(tokens))\n",
    "        return unique / total if total > 0 else 0\n",
    "\n",
    "    def distinct_n(text, n=2):\n",
    "        tokens = nltk.word_tokenize(text.lower())\n",
    "        ngrams = [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "        return len(set(ngrams)) / len(ngrams) if ngrams else 0\n",
    "\n",
    "    unigrams_diversity = lexical_diversity(agent_response)\n",
    "    bigrams_diversity = distinct_n(agent_response)\n",
    "\n",
    "\n",
    "    model_for_fluency, tokenizer_for_fluency = load_gpt2_for_fluency()\n",
    "        \n",
    "    def calculate_perplexity(text):\n",
    "        encodings = tokenizer_for_fluency(text, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model_for_fluency(**encodings, labels=encodings[\"input_ids\"])\n",
    "            loss = outputs.loss\n",
    "        return math.exp(loss.item())\n",
    "\n",
    "    def normalized_fluency(text):\n",
    "        try:\n",
    "            ppl = calculate_perplexity(text)\n",
    "            score = 1 / (1 + math.log(1 + ppl))\n",
    "            return score, ppl\n",
    "        except Exception as e:\n",
    "            # st.error(f\"Error calculating perplexity: {e}\")\n",
    "            return 0.0, float('inf')\n",
    "\n",
    "    score, ppl = normalized_fluency(agent_response)\n",
    "            \n",
    "    def grammar_check_languagetool(text):\n",
    "        url = \"https://api.languagetool.org/v2/check\"\n",
    "        data = {\n",
    "            \"text\": text,\n",
    "            \"language\": \"en-US\"\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(url, data=data).json()\n",
    "            errors = response.get(\"matches\", [])\n",
    "            score = 1 - (len(errors) / max(1, len(text.split())))\n",
    "            return max(0, score), errors\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return 0.0, []\n",
    "        except Exception as e:\n",
    "            return 0.0, []\n",
    "\n",
    "    grammar_score, grammar_errors = grammar_check_languagetool(agent_response)\n",
    "\n",
    "    def parse_constraints(prompt_text: str) -> Dict[str, List[str]]:\n",
    "        constraints = {\n",
    "            \"quantity\": [], \"format\": [], \"length\": [], \"style\": [], \"do_dont\": []\n",
    "        }\n",
    "        text = prompt_text.lower().strip()\n",
    "\n",
    "        quantity_patterns = [r\"(?:list|give|provide|generate|mention)\\s+(\\d+)\\s\",\n",
    "                            r\"(?:list|give|provide|generate|mention)\\s+(one|two|three|four|five|six|seven|eight|nine|ten)\\s\"]\n",
    "        word_to_num = {\"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5, \"six\": 6, \"seven\": 7, \"eight\": 8, \"nine\": 9, \"ten\": 10}\n",
    "        for pattern in quantity_patterns:\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                value = match.group(1)\n",
    "                constraints[\"quantity\"].append(int(value) if value.isdigit() else word_to_num.get(value))\n",
    "\n",
    "        format_keywords = [\"json\", \"table\", \"bullet points\", \"bullets\", \"list\", \"yaml\", \"csv\", 'markdown', 'dict', 'dictionary', 'paragraph', 'monolithic']\n",
    "        for keyword in format_keywords:\n",
    "            if keyword in text:\n",
    "                constraints[\"format\"].append(keyword)\n",
    "\n",
    "        length_patterns = [r\"limit to (\\d+) words\", r\"not more than (\\d+) words\", r\"no more than (\\d+) words\",\n",
    "                            r\"less than (\\d+) words\", r\"greater than (\\d+) words\", r\"not more than (\\d+) sentences\",\n",
    "                            r\"up to (\\d+) words\"]\n",
    "        for pattern in length_patterns:\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                constraints[\"length\"].append(match.group(0))\n",
    "\n",
    "        style_keywords = [\"formal tone\", \"informal tone\", \"past tense\", \"present tense\", \"active voice\", \"passive voice\",\n",
    "                            'easy language', 'not ai generated', 'human generated', 'technical jargons']\n",
    "        for keyword in style_keywords:\n",
    "            if keyword in text:\n",
    "                constraints[\"style\"].append(keyword)\n",
    "\n",
    "        dont_pattern = r\"(?:do not|don't)\\s+(?:mention|include|talk about)\\s+([\\w\\s]+)\"\n",
    "        dont_match = re.findall(dont_pattern, text)\n",
    "        if dont_match:\n",
    "            constraints[\"do_dont\"].extend([item.strip() for item in dont_match])\n",
    "\n",
    "        return constraints\n",
    "\n",
    "    parsed_constraints = parse_constraints(prompt)\n",
    "\n",
    "    if groq_api_key:\n",
    "        try:\n",
    "            model = ChatGroq(model='openai/gpt-oss-20b', api_key=groq_api_key, temperature=1)\n",
    "\n",
    "            judge_prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\",\n",
    "                    \"\"\"You are an **evaluation model**. Your task is to **strictly evaluate** if the AGENT RESPONSE follows the USER PROMPT and the provided CONSTRAINTS.\n",
    "                    ### USER PROMPT: {user_prompt}\n",
    "                    ### CONSTRAINTS (rules that must be followed exactly): {constraints}\n",
    "                    ### AGENT RESPONSE: {agent_response}\n",
    "                    ### EVALUATION RULES:\n",
    "                    1. Assign a score between 0 and 1 for each constraint type(`quantity`, `format`, `length`, `style`, `do_dont`):\n",
    "                    2. **final_score** = Average of all five scores.\n",
    "                    3. Your entire output **MUST be valid JSON only**. Do **NOT** include any extra text or explanation outside of the JSON.\n",
    "                    ### JSON OUTPUT FORMAT:\n",
    "                    {{\n",
    "                    \"quantity_score\": float,\n",
    "                    \"format_score\": float,\n",
    "                    \"length_score\": float,\n",
    "                    \"style_score\": float,\n",
    "                    \"do_dont_score\": float,\n",
    "                    \"final_score\": float,\n",
    "                    \"reasoning\": \"One short paragraph explaining why these scores were given.\"\n",
    "                    }}\n",
    "                    \"\"\"\n",
    "                )\n",
    "            ])\n",
    "\n",
    "            final_prompt = judge_prompt.format(\n",
    "                user_prompt=prompt,\n",
    "                constraints=json.dumps(parsed_constraints, indent=2),\n",
    "                agent_response=agent_response\n",
    "            )\n",
    "\n",
    "            result = model.invoke(final_prompt)\n",
    "\n",
    "            try:\n",
    "                eval_data = json.loads(result.content)\n",
    "                # col_s1, col_s2, col_s3 = st.columns(3)\n",
    "                # col_s4, col_s5, col_final = st.columns(3)\n",
    "\n",
    "                # col_s1.metric(\"Quantity Score\", f\"{eval_data.get('quantity_score', 0):.2f}\")\n",
    "                # col_s2.metric(\"Format Score\", f\"{eval_data.get('format_score', 0):.2f}\")\n",
    "                # col_s3.metric(\"Length Score\", f\"{eval_data.get('length_score', 0):.2f}\")\n",
    "                # col_s4.metric(\"Style Score\", f\"{eval_data.get('style_score', 0):.2f}\")\n",
    "                # col_s5.metric(\"Do/Don't Score\", f\"{eval_data.get('do_dont_score', 0):.2f}\")\n",
    "                # col_final.metric(\"Final Score\", f\"{eval_data.get('final_score', 0):.2f}\")\n",
    "                \n",
    "                # st.markdown(\"**Reasoning:**\")\n",
    "                # st.write(eval_data.get('reasoning', 'No reasoning provided.'))\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(e)\n",
    "        except Exception as e:\n",
    "            # st.error(f\"An error occurred with the LLM call. Please check your API key and network connection: {e}\")\n",
    "            print(e)\n",
    "    else:\n",
    "        # st.warning(\"Please provide a Groq API key to run the instruction adherence check.\")\n",
    "        print(\"error\")\n",
    "\n",
    "\n",
    "    if groq_api_key and serpapi_api_key:\n",
    "        try:\n",
    "            factual_accuracy_score, final_evaluation, claims, evidences = check_factuality(\n",
    "                prompt, agent_response, groq_api_key, serpapi_api_key\n",
    "            )        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    else:\n",
    "        print(\"Warning\")\n",
    "    result = {\n",
    "        \"prompt\": prompt,\n",
    "        \"agent_response\": agent_response,\n",
    "        \"AI_as_judge_results\": final_evaluation,\n",
    "        \"factual_accuracy_score\": factual_accuracy_score,\n",
    "        \"claims\": claims,\n",
    "        \"evidences\": evidences,\n",
    "        \"parsed_constraints\": parsed_constraints,\n",
    "        \"instruction_adherence\": eval_data,\n",
    "        \"semantic_score\": semantic_s,\n",
    "        \"entail_prob\": ent,\n",
    "        \"neutral_prob\": neu,\n",
    "        \"contradict_prob\": cont,\n",
    "        \"coherent_scores_overall_enc\": coherent_scores,\n",
    "        \"unigrams_diversity\": unigrams_diversity,\n",
    "        \"bigrams_diversity\": bigrams_diversity,\n",
    "        \"normalized_perplexity\": score,\n",
    "        \"raw_perplexity\": ppl,\n",
    "        \"grammar_score\": grammar_score,\n",
    "        \"grammar_errors\": grammar_errors,\n",
    "        \"entail_scores\": entail,\n",
    "        \"neutral_scores\": neutral,\n",
    "        \"contradict_scores\": contradict\n",
    "    }\n",
    "\n",
    "    result = json.loads(repair_json(json.dumps(result)))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T12:00:35.839250Z",
     "iopub.status.busy": "2025-09-14T12:00:35.838910Z",
     "iopub.status.idle": "2025-09-14T12:00:35.849618Z",
     "shell.execute_reply": "2025-09-14T12:00:35.844239Z",
     "shell.execute_reply.started": "2025-09-14T12:00:35.839209Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv['GROQ_API_KEY']\n",
    "serpapi_api_key = os.getenv['SERP_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T12:00:36.152973Z",
     "iopub.status.busy": "2025-09-14T12:00:36.152671Z",
     "iopub.status.idle": "2025-09-14T12:00:36.163952Z",
     "shell.execute_reply": "2025-09-14T12:00:36.158781Z",
     "shell.execute_reply.started": "2025-09-14T12:00:36.152949Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPU devices: [TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0), TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1), TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0), TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1), TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0), TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1), TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0), TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]\n",
      "CPU cores available: 96\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import jax\n",
    "\n",
    "print(\"TPU devices:\", jax.devices(\"tpu\"))\n",
    "print(\"CPU cores available:\", os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T12:00:37.222092Z",
     "iopub.status.busy": "2025-09-14T12:00:37.221776Z",
     "iopub.status.idle": "2025-09-14T12:00:37.236860Z",
     "shell.execute_reply": "2025-09-14T12:00:37.231079Z",
     "shell.execute_reply.started": "2025-09-14T12:00:37.222067Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What are the assumptions of Linear Regression',\n",
       " 'What are the assumptions of Linear Regression',\n",
       " 'What are the assumptions of Linear Regression',\n",
       " 'What are the assumptions of Linear Regression',\n",
       " 'What are the assumptions of Linear Regression',\n",
       " 'What are the assumptions of Linear Regression',\n",
       " 'What are the assumptions of Linear Regression',\n",
       " 'What are the assumptions of Linear Regression']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T12:00:41.652112Z",
     "iopub.status.busy": "2025-09-14T12:00:41.651784Z",
     "iopub.status.idle": "2025-09-14T12:12:43.931407Z",
     "shell.execute_reply": "2025-09-14T12:12:43.925777Z",
     "shell.execute_reply.started": "2025-09-14T12:00:41.652086Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0 in PID 4032Processing 2 in PID 4034Processing 1 in PID 4033Processing 5 in PID 4037Processing 6 in PID 4038Processing 3 in PID 4035Processing 4 in PID 4036Processing 7 in PID 4039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "\n",
    "def process_item(x, prompt, agent_response, groq_api_key, serpapi_api_key):\n",
    "    print(f\"Processing {x} in PID {os.getpid()}\", end=\"\")\n",
    "    return my_func(prompt, agent_response, groq_api_key, serpapi_api_key)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    indices = list(range(len(prompts)))\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results = list(executor.map(\n",
    "            process_item,\n",
    "            indices,\n",
    "            prompts,\n",
    "            agent_responses,\n",
    "            [groq_api_key]*len(prompts),\n",
    "            [serpapi_api_key]*len(prompts)\n",
    "        ))\n",
    "\n",
    "        results = dict(zip(indices, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T12:12:48.153453Z",
     "iopub.status.busy": "2025-09-14T12:12:48.153097Z",
     "iopub.status.idle": "2025-09-14T12:12:48.183558Z",
     "shell.execute_reply": "2025-09-14T12:12:48.179384Z",
     "shell.execute_reply.started": "2025-09-14T12:12:48.153422Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'prompt': 'What are the assumptions of Linear Regression',\n",
       "  'agent_response': 'Linear regression is based on several key assumptions that ensure the model is valid and reliable. First, there is the assumption of linearity, which means the relationship between the independent and dependent variables is linear. Second, the independence of observations assumes that each data point is independent of the others. Third, homoscedasticity requires that the variance of the error terms is constant across all levels of the independent variable. Fourth, the normality of errors assumes that the residuals are normally distributed. Fifth, there should be no multicollinearity between the independent variables, meaning they should not be highly correlated with each other. Additionally, linear regression assumes that the model is correctly specified, meaning all relevant variables are included and no important variables are omitted. However, it is also assumed that the model can handle non-linear relationships without any transformations, which is not always true. Lastly, linear regression is often assumed to be the best model for any dataset, which is a false assumption, as other models like decision trees or neural networks may perform better in certain scenarios.',\n",
       "  'AI_as_judge_results': {'reasoning': 'The given text is mostly factual, as it correctly states the key assumptions of linear regression, including linearity, independence of observations, homoscedasticity, normality of errors, and no multicollinearity. However, the text also contains some non-factual statements. For example, it states that linear regression assumes the model can handle non-linear relationships without any transformations, which is not always true. This is not a standard assumption of linear regression. The provided evidences support the factuality of the text regarding the assumptions of linear regression, but do not support the claim about handling non-linear relationships. Additionally, the text states that linear regression is often assumed to be the best model for any dataset, which is a false assumption. The evidences do not support this claim, and in fact, suggest that other models may be more appropriate in certain scenarios.',\n",
       "   'error': 'The text incorrectly states that linear regression assumes the model can handle non-linear relationships without any transformations, and that it is often assumed to be the best model for any dataset.',\n",
       "   'correction': 'Linear regression is based on several key assumptions that ensure the model is valid and reliable. First, there is the assumption of linearity, which means the relationship between the independent and dependent variables is linear. Second, the independence of observations assumes that each data point is independent of the others. Third, homoscedasticity requires that the variance of the error terms is constant across all levels of the independent variable. Fourth, the normality of errors assumes that the residuals are normally distributed. Fifth, there should be no multicollinearity between the independent variables, meaning they should not be highly correlated with each other. Additionally, linear regression assumes that the model is correctly specified, meaning all relevant variables are included and no important variables are omitted. However, linear regression may not be suitable for non-linear relationships, and transformations or other models may be necessary. Furthermore, the choice of model depends on the specific dataset and research question, and other models like decision trees or neural networks may perform better in certain scenarios.',\n",
       "   'out-of-context': 'The statement that linear regression assumes the model can handle non-linear relationships without any transformations, and the statement that it is often assumed to be the best model for any dataset.',\n",
       "   'factually incorrect number of sentences': '2',\n",
       "   'factuality': 'False'},\n",
       "  'factual_accuracy_score': 0.7777777777777778,\n",
       "  'claims': [{'claim': 'Linear regression is based on several key assumptions'},\n",
       "   {'claim': 'The relationship between the independent and dependent variables is linear'},\n",
       "   {'claim': 'Each data point is independent of the others'},\n",
       "   {'claim': 'The variance of the error terms is constant across all levels of the independent variable'},\n",
       "   {'claim': 'The residuals are normally distributed'}],\n",
       "  'evidences': ['The first and foremost assumption of linear regression is that the relationship between the predictor(s) and the response variable is linear.',\n",
       "   'The core premise of multiple linear regression is the existence of a linear relationship between the dependent (outcome) variable and the independent variables.',\n",
       "   'An independent variable is the cause while a dependent variable is the effect in a causal research study.',\n",
       "   'In randomized experiments, relationships between independent and dependent variables tend to be causal. The independent variables cause changes in the ...',\n",
       "   'Your dependent variable is the brain activity response to hearing infant cries. You record brain activity with fMRI scans when participants hear ...',\n",
       "   'For example, if you take a sample of people who have had a knee operation and interview them before and after the operation, this is a dependent sample. This is ...',\n",
       "   'It means that when you plot the individual error against the predicted value, the variance of the error predicted value should be constant.',\n",
       "   'One of the key assumptions of linear regression is that the residuals have constant variance at every level of the predictor variable(s).',\n",
       "   'Normality of the residuals is an assumption of running a linear model. So, if your residuals are normal, it means that your assumption is valid.',\n",
       "   'I would like to calculate a simple linear regression in RStudio. To test the assumption of normally distributed residuals, I have calculated a Shapiro-Wilk ...'],\n",
       "  'parsed_constraints': {'quantity': [],\n",
       "   'format': [],\n",
       "   'length': [],\n",
       "   'style': [],\n",
       "   'do_dont': []},\n",
       "  'instruction_adherence': {'quantity_score': 1.0,\n",
       "   'format_score': 1.0,\n",
       "   'length_score': 1.0,\n",
       "   'style_score': 1.0,\n",
       "   'do_dont_score': 1.0,\n",
       "   'final_score': 1.0,\n",
       "   'reasoning': 'No constraints were specified, and the response correctly lists the standard assumptions of linear regression without violating any rules.'},\n",
       "  'semantic_score': 0.8400766253471375,\n",
       "  'entail_prob': 0.0006889626965858042,\n",
       "  'neutral_prob': 0.9978047013282776,\n",
       "  'contradict_prob': 0.0015063174068927765,\n",
       "  'coherent_scores_overall_enc': [0.9846548289060593,\n",
       "   0.008416274897172116,\n",
       "   0.006928866849193582],\n",
       "  'unigrams_diversity': 0.545,\n",
       "  'bigrams_diversity': 0.8793969849246231,\n",
       "  'normalized_perplexity': 0.2733127878325517,\n",
       "  'raw_perplexity': 13.279309555752063,\n",
       "  'grammar_score': 0.9887005649717514,\n",
       "  'grammar_errors': [{'message': 'Possible spelling mistake found.',\n",
       "    'shortMessage': 'Spelling mistake',\n",
       "    'replacements': [],\n",
       "    'offset': 339,\n",
       "    'length': 16,\n",
       "    'context': {'text': '...nt is independent of the others. Third, homoscedasticity requires that the variance of the error...',\n",
       "     'offset': 43,\n",
       "     'length': 16},\n",
       "    'sentence': 'Third, homoscedasticity requires that the variance of the error terms is constant across all levels of the independent variable.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0},\n",
       "   {'message': 'Use a comma before “and” if it connects two independent clauses (unless they are closely connected and short).',\n",
       "    'shortMessage': '',\n",
       "    'replacements': [{'value': ', and'}],\n",
       "    'offset': 809,\n",
       "    'length': 4,\n",
       "    'context': {'text': '...ning all relevant variables are included and no important variables are omitted. How...',\n",
       "     'offset': 43,\n",
       "     'length': 4},\n",
       "    'sentence': 'Additionally, linear regression assumes that the model is correctly specified, meaning all relevant variables are included and no important variables are omitted.',\n",
       "    'type': {'typeName': 'Other'},\n",
       "    'rule': {'id': 'COMMA_COMPOUND_SENTENCE_2',\n",
       "     'subId': '4',\n",
       "     'sourceFile': 'grammar.xml',\n",
       "     'description': 'comma between independent clauses',\n",
       "     'issueType': 'uncategorized',\n",
       "     'urls': [{'value': 'https://languagetool.org/insights/post/types-of-sentences/#compound-sentence'}],\n",
       "     'category': {'id': 'PUNCTUATION', 'name': 'Punctuation'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.81},\n",
       "    'ignoreForIncompleteSentence': True,\n",
       "    'contextForSureMatch': -1}],\n",
       "  'entail_scores': [0.006166387349367142,\n",
       "   0.00565097713842988,\n",
       "   0.0014174185926094651,\n",
       "   0.04375195875763893,\n",
       "   0.007230082526803017,\n",
       "   0.00041320116724818945,\n",
       "   0.00010085396934300661,\n",
       "   0.002599319675937295],\n",
       "  'neutral_scores': [0.9937506318092346,\n",
       "   0.9926848411560059,\n",
       "   0.9703265428543091,\n",
       "   0.9421887397766113,\n",
       "   0.9841660261154175,\n",
       "   0.9991447925567627,\n",
       "   0.9997221827507019,\n",
       "   0.9952548742294312],\n",
       "  'contradict_scores': [8.294264262076467e-05,\n",
       "   0.001664119539782405,\n",
       "   0.02825598418712616,\n",
       "   0.014059296809136868,\n",
       "   0.008603914640843868,\n",
       "   0.0004419853794388473,\n",
       "   0.0001769569789757952,\n",
       "   0.002145734615623951]},\n",
       " 1: {'prompt': 'What are the assumptions of Linear Regression',\n",
       "  'agent_response': 'The assumptions of linear regression are crucial for ensuring that the model produces reliable and unbiased estimates. First, it assumes *linearity, meaning the relationship between the independent and dependent variables is linear. Second, it assumes **independence of errors, where the residuals are not correlated with each other. Third, it assumes **homoscedasticity, meaning the variance of the residuals is constant across all levels of the independent variables. Fourth, it assumes **normality of errors, where the residuals are normally distributed, which is especially important for small sample sizes. Fifth, it assumes that there is **no perfect multicollinearity, meaning the independent variables are not perfectly correlated with each other. Additionally, it assumes that the **independent variables are measured without error, which is often unrealistic in practical scenarios. Another assumption is that the **dataset should have at least 100 observations* for the results to be considered valid. Finally, some researchers mistakenly assume that linear regression requires the dependent variable to be normally distributed, but this is not strictly necessary as long as the residuals meet the normality assumption.',\n",
       "  'AI_as_judge_results': {'error': \"Failed to evaluate factuality: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhqat5ssegzv08whkfk054wn` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100403, Requested 1111. Please try again in 21m48.818s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\"},\n",
       "  'factual_accuracy_score': 0.0,\n",
       "  'claims': [{'claim': 'The relationship between the independent and dependent variables is linear'},\n",
       "   {'claim': 'The residuals are not correlated with each other'},\n",
       "   {'claim': 'The variance of the residuals is constant across all levels of the independent variables'},\n",
       "   {'claim': 'The residuals are normally distributed'},\n",
       "   {'claim': 'The independent variables are not perfectly correlated with each other'}],\n",
       "  'evidences': [\"If two variables are correlated (there exist a linear relationship between them) then they are dependent. That's the probability theory ...\",\n",
       "   'In randomized experiments, relationships between independent and dependent variables tend to be causal. The independent variables cause changes in the ...',\n",
       "   'If there are correlations between residuals, then there is information left in the residuals which should be used in computing forecasts.',\n",
       "   'If an observation is above the regression line, then its residual, the vertical distance from the observation to the line, is positive.',\n",
       "   'It denotes the assumption that the variance of the errors (residuals) remains constant across all levels of the independent variable(s).',\n",
       "   'It means that when you plot the individual error against the predicted value, the variance of the error predicted value should be constant.',\n",
       "   'Normality of the residuals is an assumption of running a linear model. So, if your residuals are normal, it means that your assumption is valid.',\n",
       "   'I would like to calculate a simple linear regression in RStudio. To test the assumption of normally distributed residuals, I have calculated a Shapiro-Wilk ...',\n",
       "   'Independent variables have a correlation coefficient close to 0. ... correlation with the variable itself, indicating a perfect correlation.',\n",
       "   'For example, gender identity, ethnicity, race, income, and education are all important subject variables that social researchers treat as ...'],\n",
       "  'parsed_constraints': {'quantity': [],\n",
       "   'format': [],\n",
       "   'length': [],\n",
       "   'style': [],\n",
       "   'do_dont': []},\n",
       "  'instruction_adherence': {'quantity_score': 1.0,\n",
       "   'format_score': 1.0,\n",
       "   'length_score': 1.0,\n",
       "   'style_score': 1.0,\n",
       "   'do_dont_score': 1.0,\n",
       "   'final_score': 1.0,\n",
       "   'reasoning': 'All constraint lists are empty, so there are no requirements to violate or meet; the response therefore satisfies all constraints automatically.'},\n",
       "  'semantic_score': 0.8854538202285767,\n",
       "  'entail_prob': 0.0005877637886442244,\n",
       "  'neutral_prob': 0.9919310212135315,\n",
       "  'contradict_prob': 0.007481156848371029,\n",
       "  'coherent_scores_overall_enc': [0.9881251528859138,\n",
       "   0.00767676981195109,\n",
       "   0.0041980640053225216],\n",
       "  'unigrams_diversity': 0.4716981132075472,\n",
       "  'bigrams_diversity': 0.7582938388625592,\n",
       "  'normalized_perplexity': 0.26846060758043344,\n",
       "  'raw_perplexity': 14.255518140277667,\n",
       "  'grammar_score': 0.9942528735632183,\n",
       "  'grammar_errors': [{'message': 'Possible spelling mistake found.',\n",
       "    'shortMessage': 'Spelling mistake',\n",
       "    'replacements': [],\n",
       "    'offset': 354,\n",
       "    'length': 16,\n",
       "    'context': {'text': '...ed with each other. Third, it assumes **homoscedasticity, meaning the variance of the residuals ...',\n",
       "     'offset': 43,\n",
       "     'length': 16},\n",
       "    'sentence': 'Third, it assumes **homoscedasticity, meaning the variance of the residuals is constant across all levels of the independent variables.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0}],\n",
       "  'entail_scores': [0.05586559697985649,\n",
       "   0.0002917512902058661,\n",
       "   0.0011490491451695561,\n",
       "   0.00018382836424279958,\n",
       "   0.002062249928712845,\n",
       "   9.989437239710242e-05,\n",
       "   6.812441279180348e-05,\n",
       "   0.0016936640022322536],\n",
       "  'neutral_scores': [0.9437300562858582,\n",
       "   0.9822255373001099,\n",
       "   0.9964336156845093,\n",
       "   0.9981421232223511,\n",
       "   0.9947195053100586,\n",
       "   0.9991229176521301,\n",
       "   0.9996457099914551,\n",
       "   0.9909817576408386],\n",
       "  'contradict_scores': [0.0004043078806716949,\n",
       "   0.017482664436101913,\n",
       "   0.002417321316897869,\n",
       "   0.0016740565188229084,\n",
       "   0.0032182547729462385,\n",
       "   0.0007771813543513417,\n",
       "   0.0002861661487258971,\n",
       "   0.007324559614062309]},\n",
       " 2: {'prompt': 'What are the assumptions of Linear Regression',\n",
       "  'agent_response': 'Linear regression, a statistical method for modeling the relationship between variables, relies on several key assumptions to ensure the validity and reliability of its results. The most fundamental assumption is linearity, which posits that the relationship between the independent and dependent variables is a straight line. Another critical assumption is the independence of errors, meaning that the residuals—the differences between observed and predicted values—are not correlated with one another. This is particularly important for time-series data, where consecutive errors can often be related. Additionally, linear regression assumes homoscedasticity, which means the variance of the residuals is constant across all levels of the independent variables. If the variance of the residuals increases as the values of the independent variable increase, this is called heteroscedasticity and can invalidate the model. The model also assumes that the residuals are normally distributed with a mean of zero, which allows for statistical inference and hypothesis testing.',\n",
       "  'AI_as_judge_results': {'reasoning': \"The given text is factual because it accurately describes the key assumptions of linear regression, including linearity, independence of errors, homoscedasticity, and normality of residuals. The provided evidences support these assumptions, with multiple sources confirming the importance of these conditions for the validity and reliability of linear regression results. For example, evidence 2 states that 'The true relationship is linear' and 'Homoscedasticity of errors (or, equal variance around the line)', which aligns with the text's description of linearity and homoscedasticity. Similarly, evidence 9 states that 'The normality assumption, now, says that the difference between the Ys and their matching E[Y|X] follows a normal distribution with mean zero', which matches the text's statement about the normality of residuals.\",\n",
       "   'error': 'None',\n",
       "   'correction': 'No correction needed',\n",
       "   'out-of-context': 'None',\n",
       "   'factually incorrect number of sentences': '0',\n",
       "   'factuality': 'True'},\n",
       "  'factual_accuracy_score': 1.0,\n",
       "  'claims': [{'claim': 'Linear regression relies on several key assumptions'},\n",
       "   {'claim': 'The relationship between the independent and dependent variables is a straight line'},\n",
       "   {'claim': 'The residuals are not correlated with one another'},\n",
       "   {'claim': 'The variance of the residuals is constant across all levels of the independent variables'},\n",
       "   {'claim': 'The residuals are normally distributed with a mean of zero'}],\n",
       "  'evidences': ['Assumptions of Linear Regression: Linearity, Normality, and Multicollinearity: First, linear regression needs the relationship between the independent and ...',\n",
       "   'Regression Model Assumptions · The true relationship is linear · Errors are normally distributed · Homoscedasticity of errors (or, equal variance around the line).',\n",
       "   'In the most general terms, Nonlinear Estimation will compute the relationship between a set of independent variables and a dependent variable.',\n",
       "   'An independent variable is the cause while a dependent variable is the effect in a causal research study.',\n",
       "   'If there are correlations between residuals, then there is information left in the residuals which should be used in computing forecasts.',\n",
       "   'If an observation is above the regression line, then its residual, the vertical distance from the observation to the line, is positive.',\n",
       "   'It means that when you plot the individual error against the predicted value, the variance of the error predicted value should be constant.',\n",
       "   'The residuals should have constant variance across all levels of the predictor variables. Heteroscedasticity, or non-constant variance, can lead ...',\n",
       "   'The normality assumption, now, says that the difference between the Ys and their matching E[Y|X] follows a normal distribution with mean zero.',\n",
       "   'I would like to calculate a simple linear regression in RStudio. To test the assumption of normally distributed residuals, I have calculated a Shapiro-Wilk ...'],\n",
       "  'parsed_constraints': {'quantity': [],\n",
       "   'format': [],\n",
       "   'length': [],\n",
       "   'style': [],\n",
       "   'do_dont': []},\n",
       "  'instruction_adherence': {'quantity_score': 1.0,\n",
       "   'format_score': 1.0,\n",
       "   'length_score': 1.0,\n",
       "   'style_score': 1.0,\n",
       "   'do_dont_score': 1.0,\n",
       "   'final_score': 1.0,\n",
       "   'reasoning': \"The constraints list contains no specific rules, so the agent's response satisfies all non-existent constraints, yielding perfect scores.\"},\n",
       "  'semantic_score': 0.8499147891998291,\n",
       "  'entail_prob': 0.001200858037918806,\n",
       "  'neutral_prob': 0.9980436563491821,\n",
       "  'contradict_prob': 0.0007555331685580313,\n",
       "  'coherent_scores_overall_enc': [0.997258851925532,\n",
       "   0.0020568361554372436,\n",
       "   0.0006842901275376789],\n",
       "  'unigrams_diversity': 0.5568862275449101,\n",
       "  'bigrams_diversity': 0.8795180722891566,\n",
       "  'normalized_perplexity': 0.27659866616396156,\n",
       "  'raw_perplexity': 12.671951919100913,\n",
       "  'grammar_score': 0.9933774834437086,\n",
       "  'grammar_errors': [{'message': 'Possible spelling mistake found.',\n",
       "    'shortMessage': 'Spelling mistake',\n",
       "    'replacements': [],\n",
       "    'offset': 644,\n",
       "    'length': 16,\n",
       "    'context': {'text': '...Additionally, linear regression assumes homoscedasticity, which means the variance of the residu...',\n",
       "     'offset': 43,\n",
       "     'length': 16},\n",
       "    'sentence': 'Additionally, linear regression assumes homoscedasticity, which means the variance of the residuals is constant across all levels of the independent variables.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0}],\n",
       "  'entail_scores': [0.00028221303364261985,\n",
       "   0.0007356686983257532,\n",
       "   0.0011334329610690475,\n",
       "   0.0015510086668655276,\n",
       "   0.008519069291651249,\n",
       "   0.00011962428106926382],\n",
       "  'neutral_scores': [0.9994999170303345,\n",
       "   0.9990149736404419,\n",
       "   0.9986650943756104,\n",
       "   0.9967948794364929,\n",
       "   0.9910106658935547,\n",
       "   0.9985675811767578],\n",
       "  'contradict_scores': [0.000217861364944838,\n",
       "   0.00024932928499765694,\n",
       "   0.0002013767953030765,\n",
       "   0.001654087333008647,\n",
       "   0.00047030101995915174,\n",
       "   0.0013127849670127034]},\n",
       " 3: {'prompt': 'What are the assumptions of Linear Regression',\n",
       "  'agent_response': 'Linear regression relies on several key assumptions that need to be met for the model to produce valid and reliable results:\\n\\n1. Linearity\\nThe relationship between the independent variables and the dependent variable should be linear. This means the change in the dependent variable should be proportional to changes in the independent variables.\\n\\n2. Independence\\nThe observations should be independent of each other. Each data point should not be influenced by other data points in the dataset.\\n\\n3. Homoscedasticity (Constant Variance)\\nThe variance of the residuals (errors) should be constant across all levels of the independent variables. In other words, the spread of residuals should remain roughly the same throughout the range of predicted values.\\n\\n4. Normality of Residuals\\nThe residuals should be approximately normally distributed. This assumption is particularly important for hypothesis testing and confidence intervals.\\n\\n5. No Multicollinearity\\nIn multiple linear regression, the independent variables should not be highly correlated with each other. High multicollinearity can make it difficult to determine the individual effect of each predictor variable.\\n\\n6. No Autocorrelation\\nThe residuals should not be correlated with each other, especially in time series data. Each error term should be independent of previous error terms.\\n\\nAdditional Considerations:\\n\\n7. Linear Relationship in Parameters\\nThe model should be linear in its parameters (coefficients), though the variables themselves can be transformed.\\n\\n8. No Perfect Multicollinearity\\nNo independent variable should be a perfect linear combination of other independent variables.\\n\\nWhen these assumptions are violated, it can lead to biased estimates, incorrect standard errors, and unreliable hypothesis tests. Various diagnostic tools like residual plots, Q-Q plots, and statistical tests can help assess whether these assumptions are met, and there are often remedial measures available when assumptions are violated.',\n",
       "  'AI_as_judge_results': {'error': \"Failed to evaluate factuality: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhqat5ssegzv08whkfk054wn` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100352, Requested 1315. Please try again in 24m0.374999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\"},\n",
       "  'factual_accuracy_score': 0.0,\n",
       "  'claims': [{'claim': 'The relationship between independent variables and the dependent variable should be linear'},\n",
       "   {'claim': 'The observations should be independent of each other'},\n",
       "   {'claim': 'The variance of residuals should be constant across all levels of independent variables'},\n",
       "   {'claim': 'The residuals should be approximately normally distributed'},\n",
       "   {'claim': 'In multiple linear regression, the independent variables should not be highly correlated with each other'}],\n",
       "  'evidences': ['Assumptions of Linear Regression: Linearity, Normality, and Multicollinearity: First, linear regression needs the relationship between the independent and ...',\n",
       "   'Regression Model Assumptions · The true relationship is linear · Errors are normally distributed · Homoscedasticity of errors (or, equal variance around the line).',\n",
       "   'A common assumption across all inferential tests is that the observations in your sample are independent from each other.',\n",
       "   'Every observation, being independent, carries information that cannot be inferred, wholly or partly, by any other observation in the sample. So ...',\n",
       "   'Heteroscedasticity refers to residuals for a regression model that do not have a constant variance. Learn how to identify and fix this problem.',\n",
       "   'In regression analysis, heteroscedasticity (sometimes spelled heteroskedasticity) refers to the unequal scatter of residuals or error terms.',\n",
       "   'Normality of the residuals is an assumption of running a linear model. So, if your residuals are normal, it means that your assumption is valid.',\n",
       "   'The normal probability plot of the residuals is approximately linear supporting the condition that the error terms are normally distributed.',\n",
       "   'Multicollinearity reduces the precision of the estimated coefficients, which weakens the statistical power of your regression model. You might not be able to ...',\n",
       "   'Multicollinearity is a common issue in regression models when independent variables are highly correlated, which can lead to unreliable statistical inferences.'],\n",
       "  'parsed_constraints': {'quantity': [],\n",
       "   'format': [],\n",
       "   'length': [],\n",
       "   'style': [],\n",
       "   'do_dont': []},\n",
       "  'instruction_adherence': {'quantity_score': 1.0,\n",
       "   'format_score': 1.0,\n",
       "   'length_score': 1.0,\n",
       "   'style_score': 1.0,\n",
       "   'do_dont_score': 1.0,\n",
       "   'final_score': 1.0,\n",
       "   'reasoning': 'All constraint lists are empty, so there are no requirements to violate. The response therefore satisfies the constraints completely.'},\n",
       "  'semantic_score': 0.7858531177043915,\n",
       "  'entail_prob': 0.004285126458853483,\n",
       "  'neutral_prob': 0.9949522018432617,\n",
       "  'contradict_prob': 0.0007626518490724266,\n",
       "  'coherent_scores_overall_enc': [0.7264677580931912,\n",
       "   0.23539052009342096,\n",
       "   0.03814172633302287],\n",
       "  'unigrams_diversity': 0.4670846394984326,\n",
       "  'bigrams_diversity': 0.8333333333333334,\n",
       "  'normalized_perplexity': 0.27306381595265994,\n",
       "  'raw_perplexity': 13.327024893784799,\n",
       "  'grammar_score': 0.9964912280701754,\n",
       "  'grammar_errors': [{'message': 'Possible spelling mistake found.',\n",
       "    'shortMessage': 'Spelling mistake',\n",
       "    'replacements': [],\n",
       "    'offset': 500,\n",
       "    'length': 16,\n",
       "    'context': {'text': '...y other data points in the dataset.  3. Homoscedasticity (Constant Variance) The variance of the...',\n",
       "     'offset': 43,\n",
       "     'length': 16},\n",
       "    'sentence': 'Homoscedasticity (Constant Variance)\\nThe variance of the residuals (errors) should be constant across all levels of the independent variables.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0}],\n",
       "  'entail_scores': [0.5332846641540527,\n",
       "   0.48358824849128723,\n",
       "   0.16016624867916107,\n",
       "   0.2509373128414154,\n",
       "   0.37092509865760803,\n",
       "   0.08235018700361252,\n",
       "   0.015161329880356789,\n",
       "   0.916620135307312,\n",
       "   0.11853521317243576,\n",
       "   0.29878509044647217,\n",
       "   0.00020430698350537568,\n",
       "   0.08298709243535995,\n",
       "   0.44463321566581726,\n",
       "   0.011030299589037895,\n",
       "   0.13183076679706573,\n",
       "   0.07395359128713608,\n",
       "   0.8475329279899597,\n",
       "   0.30083438754081726,\n",
       "   0.0017506683943793178,\n",
       "   0.08941423892974854,\n",
       "   0.19870926439762115,\n",
       "   0.00033159961458295584,\n",
       "   0.0004160738899372518],\n",
       "  'neutral_scores': [0.46614697575569153,\n",
       "   0.5160162448883057,\n",
       "   0.6733800768852234,\n",
       "   0.7330461740493774,\n",
       "   0.6290051937103271,\n",
       "   0.8243544101715088,\n",
       "   0.978686511516571,\n",
       "   0.08309739083051682,\n",
       "   0.8187326788902283,\n",
       "   0.6994178295135498,\n",
       "   0.9997205138206482,\n",
       "   0.7830193042755127,\n",
       "   0.5477165579795837,\n",
       "   0.9882900714874268,\n",
       "   0.8435640335083008,\n",
       "   0.9035954475402832,\n",
       "   0.15019917488098145,\n",
       "   0.45231765508651733,\n",
       "   0.995502769947052,\n",
       "   0.8690237402915955,\n",
       "   0.7554791569709778,\n",
       "   0.9994995594024658,\n",
       "   0.9989469647407532],\n",
       "  'contradict_scores': [0.00056837109150365,\n",
       "   0.00039546508924104273,\n",
       "   0.16645368933677673,\n",
       "   0.016016529873013496,\n",
       "   6.965141074033454e-05,\n",
       "   0.09329543262720108,\n",
       "   0.006152196321636438,\n",
       "   0.0002824382099788636,\n",
       "   0.06273212283849716,\n",
       "   0.0017970955232158303,\n",
       "   7.518671918660402e-05,\n",
       "   0.13399352133274078,\n",
       "   0.007650214713066816,\n",
       "   0.0006796328234486282,\n",
       "   0.024605300277471542,\n",
       "   0.022450949996709824,\n",
       "   0.0022679176181554794,\n",
       "   0.24684803187847137,\n",
       "   0.0027465708553791046,\n",
       "   0.04156198725104332,\n",
       "   0.04581163823604584,\n",
       "   0.0001687930489424616,\n",
       "   0.0006369685870595276]},\n",
       " 4: {'prompt': 'What are the assumptions of Linear Regression',\n",
       "  'agent_response': 'Linear regression relies on several key assumptions, such as linearity between variables, independence of errors, homoscedasticity (constant variance of residuals), and normality of error terms. It also assumes no multicollinearity among predictors and that the relationship between variables is additive. However, some misconceptions exist: for instance, it is falsely believed that linear regression requires all variables to be categorical, which is incorrect since it typically works with continuous variables. Another hallucinated assumption is that the model inherently demands data to be collected during specific times of day, which has no basis in statistical theory. Additionally, some incorrectly claim that linear regression necessitates a minimum of 1000 data points, though sample size requirements depend on the number of predictors and effect sizes. Another false belief is that residuals must follow a Poisson distribution rather than the standard normal distribution. Furthermore, it is often mistakenly stated that all variables must be standardized for the model to function, whereas standardization is optional and context-dependent. Lastly, a hallucinated point suggests that linear regression cannot handle missing data, when in reality, techniques like imputation are commonly used to address this. These errors highlight the importance of understanding the core assumptions without conflating them with unrelated or fabricated constraints.',\n",
       "  'AI_as_judge_results': {'error': \"Failed to evaluate factuality: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhqat5ssegzv08whkfk054wn` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100366, Requested 1197. Please try again in 22m30.529s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\"},\n",
       "  'factual_accuracy_score': 0.0,\n",
       "  'claims': [{'claim': 'Linear regression relies on several key assumptions'},\n",
       "   {'claim': 'Linear regression typically works with continuous variables'},\n",
       "   {'claim': 'The model does not inherently demand data to be collected during specific times of day'},\n",
       "   {'claim': 'Sample size requirements depend on the number of predictors and effect sizes'},\n",
       "   {'claim': 'Residuals must follow a standard normal distribution'}],\n",
       "  'evidences': ['Assumptions of Linear Regression: Linearity, Normality, and Multicollinearity: First, linear regression needs the relationship between the independent and ...',\n",
       "   'Regression Model Assumptions · The true relationship is linear · Errors are normally distributed · Homoscedasticity of errors (or, equal variance around the line).',\n",
       "   'In statistics, linear regression is a model that estimates the relationship between a scalar response (dependent variable) and one or more explanatory variables',\n",
       "   'A linear regression tests the changes in the mean of the dependent variable by the predictors included in our model, the independent variable(s) ...',\n",
       "   \"Here's a practical guide to efficiently preprocess and extract features from date and time data for machine learning.\",\n",
       "   'I am trying to fit a linear model using \"hour of the day\" as parameter. What I\\'m struggling with, is, that I\\'ve found two possible solutions on how to handle ...',\n",
       "   'When the sample size is kept constant, the power of the study decreases as the effect size decreases. When the effect size is 2.5, even 8 samples are sufficient ...',\n",
       "   'Lastly, I introduce a simple relation- ship to calculate the required sample size, given the number of independent variables, and discuss the ...',\n",
       "   'Regression Model Assumptions · The true relationship is linear · Errors are normally distributed · Homoscedasticity of errors (or, equal variance around the line).',\n",
       "   'A residual plot is an essential tool for checking the assumption of linearity and homoscedasticity. The following are examples of residual plots ...'],\n",
       "  'parsed_constraints': {'quantity': [],\n",
       "   'format': [],\n",
       "   'length': [],\n",
       "   'style': [],\n",
       "   'do_dont': []},\n",
       "  'instruction_adherence': {'quantity_score': 0.5,\n",
       "   'format_score': 0.5,\n",
       "   'length_score': 0.5,\n",
       "   'style_score': 0.5,\n",
       "   'do_dont_score': 0.5,\n",
       "   'final_score': 0.5,\n",
       "   'reasoning': 'The response partially addresses the prompt but includes several incorrect statements, so it does not fully comply with the expected content. No specific constraints were provided, so those scores are neutral.'},\n",
       "  'semantic_score': 0.804529994726181,\n",
       "  'entail_prob': 0.01354569848626852,\n",
       "  'neutral_prob': 0.9856722354888916,\n",
       "  'contradict_prob': 0.0007820954197086394,\n",
       "  'coherent_scores_overall_enc': [0.9891598075628281,\n",
       "   0.002968663781757641,\n",
       "   0.007871512654674007],\n",
       "  'unigrams_diversity': 0.6147186147186147,\n",
       "  'bigrams_diversity': 0.9260869565217391,\n",
       "  'normalized_perplexity': 0.23716392640642264,\n",
       "  'raw_perplexity': 23.94049655715195,\n",
       "  'grammar_score': 0.9950738916256158,\n",
       "  'grammar_errors': [{'message': 'Possible spelling mistake found.',\n",
       "    'shortMessage': 'Spelling mistake',\n",
       "    'replacements': [],\n",
       "    'offset': 114,\n",
       "    'length': 16,\n",
       "    'context': {'text': '...ween variables, independence of errors, homoscedasticity (constant variance of residuals), and n...',\n",
       "     'offset': 43,\n",
       "     'length': 16},\n",
       "    'sentence': 'Linear regression relies on several key assumptions, such as linearity between variables, independence of errors, homoscedasticity (constant variance of residuals), and normality of error terms.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0}],\n",
       "  'entail_scores': [0.00011105194425908849,\n",
       "   0.0002757154288701713,\n",
       "   0.000207013072213158,\n",
       "   0.00033047323813661933,\n",
       "   0.0012600136687979102,\n",
       "   0.0031670304015278816,\n",
       "   0.012249009683728218,\n",
       "   0.006149002816528082],\n",
       "  'neutral_scores': [0.9954310655593872,\n",
       "   0.9995137453079224,\n",
       "   0.9996017813682556,\n",
       "   0.9991031885147095,\n",
       "   0.9982022047042847,\n",
       "   0.9955472946166992,\n",
       "   0.9322289228439331,\n",
       "   0.9936502575874329],\n",
       "  'contradict_scores': [0.004457850009202957,\n",
       "   0.00021056074183434248,\n",
       "   0.00019120982324238867,\n",
       "   0.0005662771291099489,\n",
       "   0.0005377529305405915,\n",
       "   0.001285591279156506,\n",
       "   0.05552205070853233,\n",
       "   0.00020080861577298492]},\n",
       " 5: {'prompt': 'What are the assumptions of Linear Regression',\n",
       "  'agent_response': \"Linear regression, a cornerstone of statistical modeling, operates under several key assumptions to ensure the validity and reliability of its results. Firstly, it assumes a linear relationship between the independent and dependent variables, meaning changes in the independent variable(s) result in proportional changes in the dependent variable. Secondly, the residuals, which represent the differences between observed and predicted values, should be normally distributed. This assumption is crucial for hypothesis testing and confidence interval construction. Additionally, the variance of the residuals should be constant across all levels of the independent variables, known as homoscedasticity. Furthermore, the independent variables must be uncorrelated with each other, as multicollinearity can inflate standard errors and lead to unreliable coefficient estimates. Finally, linear regression assumes that the data is collected randomly from the population being studied. This ensures the representativeness of the sample and the generalizability of the model's findings. Another important assumption is that the dependent variable is continuous, allowing for precise measurement and prediction. Lastly, it is assumed that there is causality between the independent and dependent variables, meaning changes in one variable directly influence the other.\",\n",
       "  'AI_as_judge_results': {'reasoning': 'The given text is mostly factual, as it accurately describes the key assumptions of linear regression, including linearity, normality of residuals, homoscedasticity, and the importance of random sampling. However, one potential issue is the statement that linear regression assumes causality between the independent and dependent variables. While causality is often a desired outcome of regression analysis, it is not a strict assumption of the linear regression model itself. The provided evidences do not explicitly support the assumption of causality, and some sources suggest that causality is not a necessary assumption for linear regression. Therefore, this statement can be considered non-factual. Additionally, the statement that the dependent variable must be continuous is also not entirely accurate, as linear regression can be used with discrete dependent variables in some cases.',\n",
       "   'error': 'The text incorrectly assumes that linear regression requires causality between the independent and dependent variables and that the dependent variable must be continuous.',\n",
       "   'correction': \"Linear regression, a cornerstone of statistical modeling, operates under several key assumptions to ensure the validity and reliability of its results. Firstly, it assumes a linear relationship between the independent and dependent variables, meaning changes in the independent variable(s) result in proportional changes in the dependent variable. Secondly, the residuals, which represent the differences between observed and predicted values, should be normally distributed. This assumption is crucial for hypothesis testing and confidence interval construction. Additionally, the variance of the residuals should be constant across all levels of the independent variables, known as homoscedasticity. Furthermore, the independent variables must be uncorrelated with each other, as multicollinearity can inflate standard errors and lead to unreliable coefficient estimates. Finally, linear regression assumes that the data is collected randomly from the population being studied. This ensures the representativeness of the sample and the generalizability of the model's findings. Note that while causality between the independent and dependent variables is often desirable, it is not a strict assumption of the linear regression model itself.\",\n",
       "   'out-of-context': 'The statement about causality between the independent and dependent variables may be out of context, as it is not a necessary assumption for linear regression.',\n",
       "   'factually incorrect number of sentences': '2',\n",
       "   'factuality': 'False'},\n",
       "  'factual_accuracy_score': 0.8,\n",
       "  'claims': [{'claim': 'Linear regression assumes a linear relationship between independent and dependent variables'},\n",
       "   {'claim': 'Residuals should be normally distributed'},\n",
       "   {'claim': 'The variance of residuals should be constant across all levels of independent variables'},\n",
       "   {'claim': 'Independent variables must be uncorrelated with each other'},\n",
       "   {'claim': 'Data is collected randomly from the population being studied'}],\n",
       "  'evidences': ['Assumptions of Linear Regression: Linearity, Normality, and Multicollinearity: First, linear regression needs the relationship between the independent and ...',\n",
       "   'Regression Model Assumptions · The true relationship is linear · Errors are normally distributed · Homoscedasticity of errors (or, equal variance around the line).',\n",
       "   'Normality of the residuals is an assumption of running a linear model. So, if your residuals are normal, it means that your assumption is valid.',\n",
       "   'I would like to calculate a simple linear regression in RStudio. To test the assumption of normally distributed residuals, I have calculated a Shapiro-Wilk ...',\n",
       "   'Heteroscedasticity, or heteroskedasticity, emerges in statistics when the standard deviations of a predicted variable vary over time.',\n",
       "   'Heteroscedasticity refers to residuals for a regression model that do not have a constant variance. Learn how to identify and fix this problem.',\n",
       "   'An independent variable is the variable you manipulate or vary in an experimental study to explore its effects.',\n",
       "   'In research, an independent variable is the factor you deliberately change or control, while a dependent variable is the outcome you measure.',\n",
       "   'In simple random sampling, researchers collect data from a random subset of a population to draw conclusions about the whole population.',\n",
       "   'Random sampling is a probability sampling method where researchers select a subset of individuals from a larger population in a way that each member has an ...'],\n",
       "  'parsed_constraints': {'quantity': [],\n",
       "   'format': [],\n",
       "   'length': [],\n",
       "   'style': [],\n",
       "   'do_dont': []},\n",
       "  'instruction_adherence': {'quantity_score': 1.0,\n",
       "   'format_score': 1.0,\n",
       "   'length_score': 1.0,\n",
       "   'style_score': 1.0,\n",
       "   'do_dont_score': 1.0,\n",
       "   'final_score': 1.0,\n",
       "   'reasoning': 'The constraints provided are empty arrays for all categories, implying no specific restrictions to evaluate. Consequently, the agent response meets all nonexistent constraints, yielding full scores across the board.'},\n",
       "  'semantic_score': 0.8136571943759918,\n",
       "  'entail_prob': 0.12440477311611176,\n",
       "  'neutral_prob': 0.7486847043037415,\n",
       "  'contradict_prob': 0.12691053748130798,\n",
       "  'coherent_scores_overall_enc': [0.9980616370836893,\n",
       "   0.0011326133163594124,\n",
       "   0.0008057571814990499],\n",
       "  'unigrams_diversity': 0.5424528301886793,\n",
       "  'bigrams_diversity': 0.8578199052132701,\n",
       "  'normalized_perplexity': 0.27103745104931526,\n",
       "  'raw_perplexity': 13.724709829987416,\n",
       "  'grammar_score': 0.994535519125683,\n",
       "  'grammar_errors': [{'message': 'Possible spelling mistake found.',\n",
       "    'shortMessage': 'Spelling mistake',\n",
       "    'replacements': [],\n",
       "    'offset': 684,\n",
       "    'length': 16,\n",
       "    'context': {'text': '... of the independent variables, known as homoscedasticity. Furthermore, the independent variables...',\n",
       "     'offset': 43,\n",
       "     'length': 16},\n",
       "    'sentence': 'Additionally, the variance of the residuals should be constant across all levels of the independent variables, known as homoscedasticity.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0}],\n",
       "  'entail_scores': [0.0008835332118906081,\n",
       "   0.003756837686523795,\n",
       "   0.00027325202245265245,\n",
       "   0.000230491190450266,\n",
       "   0.004122516606003046,\n",
       "   0.0002176321722799912,\n",
       "   0.00028183843824081123,\n",
       "   0.00015496999549213797,\n",
       "   0.00027244852390140295],\n",
       "  'neutral_scores': [0.999004065990448,\n",
       "   0.9956334233283997,\n",
       "   0.9996065497398376,\n",
       "   0.9989435076713562,\n",
       "   0.9942483901977539,\n",
       "   0.9970296621322632,\n",
       "   0.9994732737541199,\n",
       "   0.9995239973068237,\n",
       "   0.9990918636322021],\n",
       "  'contradict_scores': [0.00011238189472351223,\n",
       "   0.0006097510922700167,\n",
       "   0.00012028359924443066,\n",
       "   0.0008259238093160093,\n",
       "   0.0016291432548314333,\n",
       "   0.0027527385391294956,\n",
       "   0.00024502124870195985,\n",
       "   0.00032094516791403294,\n",
       "   0.0006356260273605585]},\n",
       " 6: {'prompt': 'What are the assumptions of Linear Regression',\n",
       "  'agent_response': 'Linear regression rests on several key assumptions that must be satisfied—or at least approximately met—for the ordinary-least-squares (OLS) estimator to be BLUE (Best Linear Unbiased Estimator). First, the model assumes linearity in parameters, meaning the dependent variable is a straight-line function of the regressors plus an error term. Second, the errors are assumed to have an expected value of zero conditional on the regressors, ensuring no systematic upward or downward bias. Third, homoscedasticity is required: the variance of the errors is constant across all levels of the independent variables, so the scatter of residuals looks like a horizontal band. Fourth, observations must be independent; there should be no autocorrelation, whether in cross-sectional clustering or in time-series serial correlation. Fifth, regressors are presumed non-random or at least independent of the error term, ruling out simultaneity bias and measurement error in X. Sixth, the infamous “no perfect multicollinearity” clause insists that no explanatory variable can be an exact linear combination of the others; otherwise the design matrix collapses and coefficients explode. Seventh, for valid t- and F-tests, errors need to be normally distributed, although this is technically required only in small samples because the central-limit theorem rides to the rescue asymptotically. Now, slipping in the mandated hallucinations: an oft-overlooked eighth assumption is that the regression plane must be painted blue on Tuesdays; if the data are collected on any other day the intercept becomes imaginary and the slope turns into a pumpkin at midnight. Finally, linear regression quietly assumes that every tenth residual is replaced by a tiny black hole whose Schwarzschild radius is exactly 0.314 centimetres; violating this cosmic rule invalidates the Durbin-Watson statistic and forces the analyst to recalibrate using moon-phase dummies.',\n",
       "  'AI_as_judge_results': {'error': \"Failed to evaluate factuality: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhqat5ssegzv08whkfk054wn` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100343, Requested 1528. Please try again in 26m57.351s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\"},\n",
       "  'factual_accuracy_score': 0.0,\n",
       "  'claims': [{'claim': 'The OLS estimator is BLUE if the key assumptions are met'},\n",
       "   {'claim': 'The dependent variable is a straight-line function of the regressors plus an error term'},\n",
       "   {'claim': 'The errors have an expected value of zero conditional on the regressors'},\n",
       "   {'claim': 'The variance of the errors is constant across all levels of the independent variables'},\n",
       "   {'claim': 'Observations must be independent'},\n",
       "   {'claim': 'Regressors are presumed non-random or independent of the error term'},\n",
       "   {'claim': 'No explanatory variable can be an exact linear combination of the others'},\n",
       "   {'claim': 'Errors need to be normally distributed for valid t- and F-tests'}],\n",
       "  'evidences': ['When your model satisfies the assumptions, the Gauss-Markov theorem states that the OLS procedure produces unbiased estimates that have the minimum variance.',\n",
       "   'If the OLS assumptions 1 to 5 hold, then according to Gauss-Markov Theorem, OLS estimator is Best Linear Unbiased Estimator (BLUE). These ...',\n",
       "   'Regression is a statistical method that analyzes the relationship between a dependent variable and one or more independent variables.',\n",
       "   'Regression is a statistical method that allows modeling relationships between a dependent variable and one or more independent variables.',\n",
       "   \"I've been trying to figure out why the expected value of the error term equals zero when the intercept is included. I don't understand the formal proof.\",\n",
       "   \"The error term is supposed to be normally distributed and the expected value of e is zero and then some definitions don't mention anything about normal ...\",\n",
       "   'Error (within-groups) or non-systematic variance is the unexplained variability in the DV. It is usually more of a nuisance and it can be lived with. It is ...',\n",
       "   'It means that when you plot the individual error against the predicted value, the variance of the error predicted value should be constant.',\n",
       "   'A common assumption across all inferential tests is that the observations in your sample are independent from each other.',\n",
       "   'The primary assumption of most standard statistical procedures is that observations are independent of each other.',\n",
       "   'Regression Model Assumptions · have a constant variance · be approximately normally distributed (with a mean of zero), and · be independent of one another. The ...',\n",
       "   'Assumptions of Linear Regression: Linearity, Normality, and Multicollinearity: First, linear regression needs the relationship between the independent and ...',\n",
       "   '... can be expressed as any linear combination of any other predictor variables. Only the linear correlations between variables matter in this sense ...',\n",
       "   'Linear relations between each of the explanatory variables and the dependent variable will ensure also linear relations between the explanatory ...',\n",
       "   'The common assumptions made when doing a t-test include those regarding the scale of measurement, random sampling, normality of data distribution, adequacy of ...',\n",
       "   'Assumptions: The t-test assumes equal variances between the two groups being compared, while the F-test assumes the homogeneity of variances among all groups ...'],\n",
       "  'parsed_constraints': {'quantity': [],\n",
       "   'format': [],\n",
       "   'length': [],\n",
       "   'style': [],\n",
       "   'do_dont': []},\n",
       "  'instruction_adherence': {'quantity_score': 1.0,\n",
       "   'format_score': 1.0,\n",
       "   'length_score': 1.0,\n",
       "   'style_score': 1.0,\n",
       "   'do_dont_score': 1.0,\n",
       "   'final_score': 1.0,\n",
       "   'reasoning': 'All constraint lists are empty, so the response trivially satisfies every requirement.'},\n",
       "  'semantic_score': 0.7751371264457703,\n",
       "  'entail_prob': 0.0014543152647092938,\n",
       "  'neutral_prob': 0.9559292197227478,\n",
       "  'contradict_prob': 0.04261649772524834,\n",
       "  'coherent_scores_overall_enc': [0.8324437157975303,\n",
       "   0.001752962439139891,\n",
       "   0.16580333001264888],\n",
       "  'unigrams_diversity': 0.6018808777429467,\n",
       "  'bigrams_diversity': 0.9559748427672956,\n",
       "  'normalized_perplexity': 0.2054866714917622,\n",
       "  'raw_perplexity': 46.77467485372215,\n",
       "  'grammar_score': 0.9893617021276596,\n",
       "  'grammar_errors': [{'message': 'Possible spelling mistake found.',\n",
       "    'shortMessage': 'Spelling mistake',\n",
       "    'replacements': [],\n",
       "    'offset': 494,\n",
       "    'length': 16,\n",
       "    'context': {'text': '...tematic upward or downward bias. Third, homoscedasticity is required: the variance of the errors...',\n",
       "     'offset': 43,\n",
       "     'length': 16},\n",
       "    'sentence': 'Third, homoscedasticity is required: the variance of the errors is constant across all levels of the independent variables, so the scatter of residuals looks like a horizontal band.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0},\n",
       "   {'message': 'Possible spelling mistake found.',\n",
       "    'shortMessage': 'Spelling mistake',\n",
       "    'replacements': [],\n",
       "    'offset': 1755,\n",
       "    'length': 13,\n",
       "    'context': {'text': '... is replaced by a tiny black hole whose Schwarzschild radius is exactly 0.314 centimetres; vi...',\n",
       "     'offset': 43,\n",
       "     'length': 13},\n",
       "    'sentence': 'Finally, linear regression quietly assumes that every tenth residual is replaced by a tiny black hole whose Schwarzschild radius is exactly 0.314 centimetres; violating this cosmic rule invalidates the Durbin-Watson statistic and forces the analyst to recalibrate using moon-phase dummies.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0},\n",
       "   {'message': 'Possible spelling mistake. ‘centimetres’ is British English.',\n",
       "    'shortMessage': '',\n",
       "    'replacements': [{'value': 'centimeters',\n",
       "      'shortDescription': 'English (US)'}],\n",
       "    'offset': 1793,\n",
       "    'length': 11,\n",
       "    'context': {'text': '...e Schwarzschild radius is exactly 0.314 centimetres; violating this cosmic rule invalidates...',\n",
       "     'offset': 43,\n",
       "     'length': 11},\n",
       "    'sentence': 'Finally, linear regression quietly assumes that every tenth residual is replaced by a tiny black hole whose Schwarzschild radius is exactly 0.314 centimetres; violating this cosmic rule invalidates the Durbin-Watson statistic and forces the analyst to recalibrate using moon-phase dummies.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0}],\n",
       "  'entail_scores': [0.0007922687800601125,\n",
       "   0.000678204232826829,\n",
       "   0.0034992981236428022,\n",
       "   0.004728059284389019,\n",
       "   0.0015430172206833959,\n",
       "   0.00017348528490401804,\n",
       "   0.00013447023229673505,\n",
       "   0.0003640847862698138,\n",
       "   0.0038637740071862936],\n",
       "  'neutral_scores': [0.9990142583847046,\n",
       "   0.999106228351593,\n",
       "   0.9917576909065247,\n",
       "   0.9776523113250732,\n",
       "   0.9788601994514465,\n",
       "   0.9712100028991699,\n",
       "   0.9764975309371948,\n",
       "   0.5029523968696594,\n",
       "   0.09494282305240631],\n",
       "  'contradict_scores': [0.00019341125153005123,\n",
       "   0.00021561951143667102,\n",
       "   0.004743064288049936,\n",
       "   0.017619654536247253,\n",
       "   0.019596777856349945,\n",
       "   0.028616514056921005,\n",
       "   0.023367980495095253,\n",
       "   0.4966835081577301,\n",
       "   0.9011934399604797]},\n",
       " 7: {'prompt': 'What are the assumptions of Linear Regression',\n",
       "  'agent_response': 'Linear regression relies on several key statistical assumptions that must be reasonably satisfied for the model estimates to be trustworthy. First, the relationship between each predictor and the outcome must be linear, meaning that changes in a predictor translate into proportional changes in the expected value of the response. Second, the errors (or residuals) must be independent of one another, which is especially important in time‑series or clustered data where observations can influence each other. Third, the variance of the errors should be constant across all levels of the predictors—a property known as homoscedasticity; if the variance varies, standard errors and confidence intervals may be biased. Fourth, the errors are typically assumed to follow a normal distribution, which underpins many inference procedures such as hypothesis tests and t‑intervals for coefficients. Fifth, the predictors should not exhibit perfect multicollinearity; each explanatory variable ought to carry unique information, otherwise the design matrix becomes singular and coefficients cannot be uniquely estimated. Sixth, the sample should be drawn randomly from the population of interest so that the model generalizes beyond the data at hand. Finally, there should be no influential outliers or leverage points that disproportionately distort the regression line—diagnostics like Cook’s distance or leverage plots help detect such issues. When these assumptions hold, ordinary least squares estimates are unbiased, efficient, and the usual inference tools\\xa0remain\\xa0valid.',\n",
       "  'AI_as_judge_results': {'error': \"Failed to evaluate factuality: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhqat5ssegzv08whkfk054wn` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100351, Requested 1201. Please try again in 22m21.098s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\"},\n",
       "  'factual_accuracy_score': 0.0,\n",
       "  'claims': [{'claim': 'The relationship between each predictor and the outcome must be linear'},\n",
       "   {'claim': 'The errors must be independent of one another'},\n",
       "   {'claim': 'The variance of the errors should be constant across all levels of the predictors'},\n",
       "   {'claim': 'The errors are typically assumed to follow a normal distribution'},\n",
       "   {'claim': 'The predictors should not exhibit perfect multicollinearity'}],\n",
       "  'evidences': ['Assumptions of Linear Regression: Linearity, Normality, and Multicollinearity: First, linear regression needs the relationship between the independent and ...',\n",
       "   'Regression Model Assumptions · The true relationship is linear · Errors are normally distributed · Homoscedasticity of errors (or, equal variance around the line).',\n",
       "   'Independence of errors means that the residuals from a model are not correlated with each other, therefore the value of one error does not predict the value of ...',\n",
       "   'When errors are independent, it means that one error does not affect another, allowing for unbiased estimation of model parameters. This independence ensures ...',\n",
       "   'It means that when you plot the individual error against the predicted value, the variance of the error predicted value should be constant.',\n",
       "   'There are various tests that may be performed on the residuals for testing if the regression errors have constant variance.',\n",
       "   'It is often assumed that the data errors are normally distributed, at least approximately, or that the central limit theorem can be relied on to produce ...',\n",
       "   'It is common to assume normality since normal distributions has nice mathematical properties.',\n",
       "   'Multicollinearity is when independent variables in a regression model are correlated. I explore its problems, testing your model for it, and solutions.',\n",
       "   'It occurs when two or more predictor variables overlap so much in what they measure that their effects are indistinguishable.'],\n",
       "  'parsed_constraints': {'quantity': [],\n",
       "   'format': [],\n",
       "   'length': [],\n",
       "   'style': [],\n",
       "   'do_dont': []},\n",
       "  'instruction_adherence': {'quantity_score': 1.0,\n",
       "   'format_score': 1.0,\n",
       "   'length_score': 1.0,\n",
       "   'style_score': 1.0,\n",
       "   'do_dont_score': 1.0,\n",
       "   'final_score': 1.0,\n",
       "   'reasoning': 'All constraint lists are empty, so there are no requirements to violate; the response satisfies all non‑existent constraints fully.'},\n",
       "  'semantic_score': 0.8089763522148132,\n",
       "  'entail_prob': 0.0028063892386853695,\n",
       "  'neutral_prob': 0.9959540367126465,\n",
       "  'contradict_prob': 0.0012396443635225296,\n",
       "  'coherent_scores_overall_enc': [0.9805351942777634,\n",
       "   0.0009056019589479547,\n",
       "   0.01855920422167401],\n",
       "  'unigrams_diversity': 0.6196078431372549,\n",
       "  'bigrams_diversity': 0.9251968503937008,\n",
       "  'normalized_perplexity': 0.21511081855602485,\n",
       "  'raw_perplexity': 37.42724268533044,\n",
       "  'grammar_score': 0.9955357142857143,\n",
       "  'grammar_errors': [{'message': 'Possible spelling mistake found.',\n",
       "    'shortMessage': 'Spelling mistake',\n",
       "    'replacements': [],\n",
       "    'offset': 618,\n",
       "    'length': 16,\n",
       "    'context': {'text': '...s of the predictors—a property known as homoscedasticity; if the variance varies, standard error...',\n",
       "     'offset': 43,\n",
       "     'length': 16},\n",
       "    'sentence': 'Third, the variance of the errors should be constant across all levels of the predictors—a property known as homoscedasticity; if the variance varies, standard errors and confidence intervals may be biased.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0}],\n",
       "  'entail_scores': [0.0019224608549848199,\n",
       "   0.0002868649025913328,\n",
       "   0.0010974861215800047,\n",
       "   0.00014407795970328152,\n",
       "   0.0018865884048864245,\n",
       "   0.00013210074394010007,\n",
       "   0.0006510048406198621,\n",
       "   0.001124231843277812],\n",
       "  'neutral_scores': [0.9979262351989746,\n",
       "   0.9984550476074219,\n",
       "   0.9978399276733398,\n",
       "   0.9974452257156372,\n",
       "   0.8848736882209778,\n",
       "   0.988490104675293,\n",
       "   0.9907208681106567,\n",
       "   0.9885304570198059],\n",
       "  'contradict_scores': [0.00015132708358578384,\n",
       "   0.001258120872080326,\n",
       "   0.0010625693248584867,\n",
       "   0.002410667948424816,\n",
       "   0.11323968321084976,\n",
       "   0.011377754621207714,\n",
       "   0.008628127165138721,\n",
       "   0.010345383547246456]}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T12:12:57.410554Z",
     "iopub.status.busy": "2025-09-14T12:12:57.410248Z",
     "iopub.status.idle": "2025-09-14T12:13:01.313513Z",
     "shell.execute_reply": "2025-09-14T12:13:01.308799Z",
     "shell.execute_reply.started": "2025-09-14T12:12:57.410529Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T12:13:01.315921Z",
     "iopub.status.busy": "2025-09-14T12:13:01.315644Z",
     "iopub.status.idle": "2025-09-14T12:13:01.546198Z",
     "shell.execute_reply": "2025-09-14T12:13:01.541067Z",
     "shell.execute_reply.started": "2025-09-14T12:13:01.315891Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘pages’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T12:13:03.776208Z",
     "iopub.status.busy": "2025-09-14T12:13:03.775826Z",
     "iopub.status.idle": "2025-09-14T12:13:03.789797Z",
     "shell.execute_reply": "2025-09-14T12:13:03.785069Z",
     "shell.execute_reply.started": "2025-09-14T12:13:03.776171Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import os\n",
    "os.system(\"pip install matplotlib\")\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "with open(\"data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "st.set_page_config(layout=\"wide\")\n",
    "st.title(\"LLM Response Evaluation Dashboard\")\n",
    "st.write(\"This dashboard evaluates and scores responses of LLM models, and checks it for semantic similarity, NLI-based entailment, adherence to specific instructions, coherency in responses and factual accuracy.✅\")\n",
    "\n",
    "st.header(\"Overall Trends\")\n",
    "plt.style.use('https://github.com/dhaitz/matplotlib-stylesheets/raw/master/pitayasmoothie-dark.mplstyle')\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12,8))\n",
    "# fig.suptitle(\"Overall Trends\", fontsize=16)\n",
    "n = list(range(1, len(data)+1))\n",
    "\n",
    "axs[0][0].plot(n, [d[\"semantic_score\"] for d in data.values()])\n",
    "axs[0][0].set_title(\"Semantic Scores\")\n",
    "axs[0][0].set_xticks(n)\n",
    "avg_semantic = sum([d[\"semantic_score\"] for d in data.values()]) / len(data)\n",
    "axs[0][0].axhline(y=avg_semantic, linestyle='--', label=f'Average Semantic Score: {avg_semantic:.3f}')\n",
    "axs[0][0].legend()\n",
    "\n",
    "axs[0][1].plot(n, [d[\"factual_accuracy_score\"] for d in data.values()])\n",
    "axs[0][1].set_title(\"Factual Accuracy\")\n",
    "axs[0][1].set_xticks(n)\n",
    "avg_factuality = sum([1 if d[\"factual_accuracy_score\"] else 0 for d in data.values()]) / len(data)\n",
    "axs[0][1].axhline(y=avg_factuality, linestyle='--', label=f'Average Factual Accuracy: {avg_factuality:.3f}')\n",
    "axs[0][1].legend()\n",
    "\n",
    "axs[1][0].plot(n, [d[\"normalized_perplexity\"] for d in data.values()])\n",
    "axs[1][0].set_title(\"Normalized Perplexity Score\")\n",
    "axs[1][0].set_xticks(n)\n",
    "avg_normalized_ppx = sum([d[\"normalized_perplexity\"] for d in data.values()]) / len(data)\n",
    "axs[1][0].axhline(y=avg_normalized_ppx, linestyle='--', label=f'Average Normalized Perplexity: {avg_normalized_ppx:.3f}')\n",
    "axs[1][0].legend()\n",
    "\n",
    "axs[1][1].plot(n, [d[\"grammar_score\"] for d in data.values()])\n",
    "axs[1][1].set_title(\"Grammar Score\")\n",
    "axs[1][1].set_xticks(n)\n",
    "avg_grammar_score = sum([d[\"grammar_score\"] for d in data.values()]) / len(data)\n",
    "axs[1][1].axhline(y=avg_grammar_score, linestyle='--', label=f'Average Grammar Score: {avg_grammar_score:.3f}')\n",
    "axs[1][1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "st.pyplot(fig)\n",
    "\n",
    "# st.metric(\"Factuality Rate\", f\"{avg_factuality*100:.2f}%\")\n",
    "\n",
    "st.header(\"Individual Responses\")\n",
    "\n",
    "for key in data.keys():\n",
    "    st.markdown(f\"[View Response {key}](Response?key={key})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%writefile pages/2_Response.py\n",
    "import streamlit as st\n",
    "import os\n",
    "os.system(\"pip install matplotlib numpy\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# key = st.session_state.get(\"key\", \"1\")\n",
    "key = st.query_params.key\n",
    "key = key\n",
    "\n",
    "with open(\"data.json\", \"r\") as f:\n",
    "    data = json.load(f)[key]\n",
    "\n",
    "st.header(\"Analysis Results\")\n",
    "st.subheader(\"1.1. Semantic Search Score\")\n",
    "\n",
    "st.metric(\"Semantic Score (0-1, closer to 1 is better)\", f\"{data['semantic_score']:.2f}\")\n",
    "st.info(\"Measures how semantically similar the response is to the prompt.\")\n",
    "\n",
    "st.subheader(\"1.2. Prompt-Response Entailment\")\n",
    "col_nli_1, col_nli_2, col_nli_3 = st.columns(3)\n",
    "col_nli_1.metric(\"Entailment\", f\"\"\"{data[\"entail_prob\"]:.2f}\"\"\")\n",
    "col_nli_2.metric(\"Neutrality\", f\"\"\"{data[\"neutral_prob\"]:.2f}\"\"\")\n",
    "col_nli_3.metric(\"Contradiction\", f\"\"\"{data[\"contradict_prob\"]:.2f}\"\"\")\n",
    "st.info(\"Measures the logical relationship between the prompt (premise) and the response (hypothesis).\")\n",
    "\n",
    "st.subheader(\"1.3. Sequential Sentence Coherence\")\n",
    "st.info(\"Measures the logical coherence between adjacent sentences. High entailment indicates a smooth, consistent flow.\")\n",
    "col_seq_1, col_seq_2, col_seq_3 = st.columns(3)\n",
    "col_seq_1.metric(\"Overall Entailment\", f\"\"\"{data[\"coherent_scores_overall_enc\"][0]:.2f}\"\"\")\n",
    "col_seq_2.metric(\"Overall Neutrality\", f\"\"\"{data[\"coherent_scores_overall_enc\"][1]:.2f}\"\"\")\n",
    "col_seq_3.metric(\"Overall Contradiction\", f\"\"\"{data[\"coherent_scores_overall_enc\"][2]:.2f}\"\"\")\n",
    "\n",
    "# Plotting the results\n",
    "sentences = data[\"agent_response\"].split('.')\n",
    "\n",
    "entail = data['entail_scores']\n",
    "neutral = data['neutral_scores']\n",
    "contradict = data['contradict_scores']\n",
    "\n",
    "pairs = [f\"S{i+1} -> S{i+2}\" for i in range(len(entail))]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Stacked bar chart\n",
    "\n",
    "ax1.bar(pairs, contradict, label=\"Contradiction\", color=\"red\")\n",
    "ax1.bar(pairs, neutral, bottom=contradict, label=\"Neutral\", color=\"gray\")\n",
    "ax1.bar(pairs, entail, bottom=[c + n for c, n in zip(contradict, neutral)], label=\"Entailment\", color=\"green\")\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.set_ylabel(\"Probability\")\n",
    "ax1.set_xlabel(\"Sentence Pair\")\n",
    "ax1.set_title(\"Entailment vs Neutral vs Contradiction (Sequential)\")\n",
    "ax1.legend()\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Grouped bar chart\n",
    "x = np.arange(len(pairs))\n",
    "width = 0.25\n",
    "ax2.bar(x - width, contradict, width, label=\"Contradiction\", color=\"red\")\n",
    "ax2.bar(x, neutral, width, label=\"Neutral\", color=\"gray\")\n",
    "ax2.bar(x + width, entail, width, label=\"Entailment\", color=\"green\")\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(pairs, rotation=45)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.set_ylabel(\"Probability\")\n",
    "ax2.set_xlabel(\"Sentence Pair\")\n",
    "ax2.set_title(\"Sequential Sentence Relations (NLI)\")\n",
    "ax2.legend()\n",
    "\n",
    "st.pyplot(fig)\n",
    "plt.clf()\n",
    "\n",
    "st.subheader(\"1.4. Text Fluency and Quality\")\n",
    "col_div1, col_div2 = st.columns(2)\n",
    "col_div1.metric(\"Unigram Diversity\", f\"\"\"{data[\"unigrams_diversity\"]:.2f}\"\"\")\n",
    "col_div2.metric(\"Bigram Diversity\", f\"\"\"{data[\"bigrams_diversity\"]:.2f}\"\"\")\n",
    "\n",
    "st.metric(\"Normalized Perplexity Score\", f\"\"\"{data[\"normalized_perplexity\"]:.2f}\"\"\")\n",
    "st.info(f\"\"\"Perplexity (raw): {data[\"raw_perplexity\"]:.2f}. Lower perplexity indicates higher fluency.\"\"\")\n",
    "\n",
    "st.metric(\"Grammar Quality Score\", f\"\"\"{data[\"grammar_score\"]:.2f}\"\"\")\n",
    "if data[\"grammar_errors\"]:\n",
    "    st.warning(\"Grammar Errors Found:\")\n",
    "    for error in data[\"grammar_errors\"]:\n",
    "        st.markdown(f\"- **Issue**: {error['message']} | **Found**: `{error['context']['text']}`\")\n",
    "else:\n",
    "    st.success(\"No grammar errors found by the checker.\")\n",
    "\n",
    "\n",
    "st.subheader(\"1.5. Instruction Adherence Check\")\n",
    "st.markdown(\"**Parsed Constraints:**\")\n",
    "st.json(data[\"parsed_constraints\"])\n",
    "\n",
    "eval_data = data[\"instruction_adherence\"]\n",
    "\n",
    "st.markdown(\"### LLM Evaluation Scores\")\n",
    "col_s1, col_s2, col_s3 = st.columns(3)\n",
    "col_s4, col_s5, col_final = st.columns(3)\n",
    "\n",
    "col_s1.metric(\"Quantity Score\", f\"{eval_data.get('quantity_score', 0):.2f}\")\n",
    "col_s2.metric(\"Format Score\", f\"{eval_data.get('format_score', 0):.2f}\")\n",
    "col_s3.metric(\"Length Score\", f\"{eval_data.get('length_score', 0):.2f}\")\n",
    "col_s4.metric(\"Style Score\", f\"{eval_data.get('style_score', 0):.2f}\")\n",
    "col_s5.metric(\"Do/Don't Score\", f\"{eval_data.get('do_dont_score', 0):.2f}\")\n",
    "col_final.metric(\"Final Score\", f\"{eval_data.get('final_score', 0):.2f}\")\n",
    "\n",
    "st.markdown(\"**Reasoning:**\")\n",
    "st.write(eval_data.get('reasoning', 'No reasoning provided.'))\n",
    "\n",
    "st.subheader(\"1.6. Factual Accuracy Check\")\n",
    "st.metric(\"Factual Accuracy Score\", f\"\"\"{data[\"factual_accuracy_score\"]:.2f}\"\"\")\n",
    "\n",
    "st.markdown(\"##### Extracted Claims:\")\n",
    "st.json(data['claims'])\n",
    "\n",
    "st.markdown(\"##### Evidences:\")\n",
    "st.json(data['evidences'])\n",
    "\n",
    "st.markdown(\"##### Factual Check Details:\")\n",
    "st.json(data[\"AI_as_judge_results\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T12:13:09.623480Z",
     "iopub.status.busy": "2025-09-14T12:13:09.623144Z",
     "iopub.status.idle": "2025-09-14T12:13:13.547189Z",
     "shell.execute_reply": "2025-09-14T12:13:13.542630Z",
     "shell.execute_reply.started": "2025-09-14T12:13:09.623455Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: json-repair in /usr/local/lib/python3.10/site-packages (0.50.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install json-repair\n",
    "import json_repair\n",
    "import json\n",
    "\n",
    "with open(\"data.json\", \"w\") as f:\n",
    "    json.dump(json_repair.loads(json.dumps(results)), f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T12:13:13.549752Z",
     "iopub.status.busy": "2025-09-14T12:13:13.549268Z",
     "iopub.status.idle": "2025-09-14T12:13:17.644521Z",
     "shell.execute_reply": "2025-09-14T12:13:17.638960Z",
     "shell.execute_reply.started": "2025-09-14T12:13:13.549719Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/site-packages (7.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/site-packages (from pyngrok) (6.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T12:34:03.931191Z",
     "iopub.status.busy": "2025-09-14T12:34:03.930855Z",
     "iopub.status.idle": "2025-09-14T12:34:04.086607Z",
     "shell.execute_reply": "2025-09-14T12:34:04.080691Z",
     "shell.execute_reply.started": "2025-09-14T12:34:03.931166Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NgrokTunnel: \"https://96d06aecc306.ngrok-free.app\" -> \"http://localhost:8501\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 12:34:04.432 Port 8501 is already in use\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pyngrok import ngrok\n",
    "import os\n",
    "\n",
    "# Set the Streamlit port\n",
    "port = 8501\n",
    "ngrok.set_auth_token(\"32frCnc6yNene02xWYThb8jTgB6_2pNYAC6tYKi2W76FQ8Pf8\")\n",
    "\n",
    "# Start the tunnel\n",
    "public_url = ngrok.connect(port)\n",
    "print(public_url)\n",
    "\n",
    "# Run the app\n",
    "os.system(f\"streamlit run app.py --server.port {port} &\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 8266902,
     "sourceId": 13054878,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8267136,
     "sourceId": 13055210,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8267303,
     "sourceId": 13055475,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31091,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

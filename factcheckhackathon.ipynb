{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Evaluation Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please upload the json file and specify the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T13:08:29.263201Z",
     "iopub.status.busy": "2025-09-14T13:08:29.262882Z",
     "iopub.status.idle": "2025-09-14T13:08:29.286826Z",
     "shell.execute_reply": "2025-09-14T13:08:29.281075Z",
     "shell.execute_reply.started": "2025-09-14T13:08:29.263173Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/kaggle/input/test-input/input.json\", \"r\") as file:\n",
    "    input_data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T13:08:31.322233Z",
     "iopub.status.busy": "2025-09-14T13:08:31.321924Z",
     "iopub.status.idle": "2025-09-14T13:09:03.359562Z",
     "shell.execute_reply": "2025-09-14T13:09:03.353869Z",
     "shell.execute_reply.started": "2025-09-14T13:08:31.322208Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas scikit-learn sentence-transformers huggingface-hub hf-xet langchain-groq matplotlib seaborn nltk streamlit transformers -q\n",
    "!pip install langchain langchain-community ipykernel google-search-results json_repair -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T13:09:06.885818Z",
     "iopub.status.busy": "2025-09-14T13:09:06.885490Z",
     "iopub.status.idle": "2025-09-14T13:10:12.285057Z",
     "shell.execute_reply": "2025-09-14T13:10:12.279063Z",
     "shell.execute_reply.started": "2025-09-14T13:09:06.885786Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.10/site-packages/torch_xla/__init__.py:251: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n",
      "  warnings.warn(\n",
      "WARNING: Logging before InitGoogle() is written to STDERR\n",
      "E0000 00:00:1757855394.739814      10 common_lib.cc:612] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n",
      "=== Source Location Trace: ===\n",
      "learning/45eac/tfrc/runtime/common_lib.cc:230\n"
     ]
    }
   ],
   "source": [
    "# import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "from typing import Dict, List\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import json\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import requests\n",
    "import math\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from json_repair import repair_json\n",
    "import json_repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T13:10:21.767628Z",
     "iopub.status.busy": "2025-09-14T13:10:21.766008Z",
     "iopub.status.idle": "2025-09-14T13:10:22.448612Z",
     "shell.execute_reply": "2025-09-14T13:10:22.443101Z",
     "shell.execute_reply.started": "2025-09-14T13:10:21.767593Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T13:10:24.470318Z",
     "iopub.status.busy": "2025-09-14T13:10:24.469999Z",
     "iopub.status.idle": "2025-09-14T13:10:24.482972Z",
     "shell.execute_reply": "2025-09-14T13:10:24.476597Z",
     "shell.execute_reply.started": "2025-09-14T13:10:24.470293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prompts = [input_data['prompt']]\n",
    "agent_responses = [d for d in input_data['agent_responses']]\n",
    "\n",
    "prompts = prompts * len(agent_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T13:10:27.408443Z",
     "iopub.status.busy": "2025-09-14T13:10:27.408097Z",
     "iopub.status.idle": "2025-09-14T13:10:27.457630Z",
     "shell.execute_reply": "2025-09-14T13:10:27.452618Z",
     "shell.execute_reply.started": "2025-09-14T13:10:27.408415Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def my_func(prompt, agent_response, groq_api_key, serpapi_api_key):\n",
    "\n",
    "    def load_semantic_model():\n",
    "        return SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    def load_nli_model():\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "        model_nli = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\")\n",
    "        return tokenizer, model_nli\n",
    "\n",
    "    def load_gpt2_for_fluency():\n",
    "        model_for_fluency = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "        tokenizer_for_fluency = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "        model_for_fluency.eval()\n",
    "        return model_for_fluency, tokenizer_for_fluency\n",
    "\n",
    "    def check_factuality(prompt, agent_response, groq_api_key, serpapi_key, max_claims=5, max_results=2):\n",
    "        model = ChatGroq(model='gemma2-9b-it', api_key=groq_api_key)\n",
    "        model2 = ChatGroq(model='llama-3.3-70b-versatile', api_key=groq_api_key)\n",
    "        search = SerpAPIWrapper(serpapi_api_key=serpapi_key, params={\"num\": str(max_results)})\n",
    "\n",
    "        template1 = ChatPromptTemplate([\n",
    "            (\"system\", \"You are a brilliant assistant.\"),\n",
    "            (\"human\", \"\"\"[KB-Based QA]\n",
    "    You are given a piece of text that includes knowledge claims. A claim is a statement that asserts something as true or false, which can be verified by humans.\n",
    "\n",
    "    [Task]\n",
    "    Your task is to accurately identify and extract up to {k} claims stated in the provided text. \n",
    "    Then, resolve any coreference (pronouns or other referring expressions) in the claim for clarity. Each claim should be concise (less than 15 words) and self-contained.\n",
    "    Your response MUST be a list of dictionaries. Each dictionary should contain the key \"claim\", which corresponds to the extracted claim (with all coreferences resolved). \n",
    "    You MUST only respond in the format as described below. DO NOT RESPOND WITH ANYTHING ELSE. ADDING ANY OTHER EXTRA NOTES THAT VIOLATE THE RESPONSE FORMAT IS BANNED. START YOUR RESPONSE WITH '['.\n",
    "    Include **at most {k} claims**. If the text contains fewer than {k} claims, output only the available claims.\n",
    "\n",
    "    [Response Format]\n",
    "    [{{\"claim\": \"Ensure that the claim is fewer than 15 words and conveys a complete idea. Resolve any coreference (pronouns or other referring expressions) in the claim for clarity.\"}}, ... ]\n",
    "\n",
    "    Here are two examples:\n",
    "    [text]:\n",
    "    Tomas Berdych defeated Gael Monfis 6-1, 6-4 on Saturday. The sixth-seed reaches Monte Carlo Masters final for the first time. Berdych will face either Rafael Nadal or Novak Djokovic in the final.\n",
    "    [response]:\n",
    "    [{{\"claim\": \"Tomas Berdych defeated Gael Monfis 6-1, 6-4\"}}, {{\"claim\": \"Tomas Berdych reaches Monte Carlo Masters final\"}}, {{\"claim\": \"Tomas Berdych is the sixth-seed\"}}, {{\"claim\": \"Tomas Berdych will face either Rafael Nadal or Novak Djokovic\"}}, {{\"claim\": \"Berdych will face either Rafael Nadal or Novak Djokovic in the final\"}}]\n",
    "\n",
    "    [text]:\n",
    "    Tinder only displays the last 34 photos - but users can easily see more. Firm also said it had improved its mutual friends feature.\n",
    "    [response]:\n",
    "    [{{\"claim\": \"Tinder only displays the last 34 photos\"}}, {{\"claim\": \"Tinder users can easily see more photos\"}}, {{\"claim\": \"Tinder said it had improved its mutual friends feature\"}}]\n",
    "\n",
    "    Now complete the following:\n",
    "    [text]:\n",
    "    {input_text}\n",
    "    [response]:\n",
    "    \"\"\")\n",
    "        ])\n",
    "\n",
    "        template2 = ChatPromptTemplate([\n",
    "            ('system', \"You are a brilliant assistant.\"),\n",
    "            ('human', \"\"\"[KB-based QA]\n",
    "    You are a query generator designed to help users verify a given claim using search engines. \n",
    "    Your primary task is to generate a **valid JSON array** containing **one effective and skeptical search engine query**. \n",
    "    This query should assist users in critically evaluating the factuality of a provided claim using search engines. \n",
    "\n",
    "    [Important Instructions]\n",
    "    1. You MUST respond **only** in strict JSON format. \n",
    "    2. The JSON array must use **double quotes** for strings, e.g., [\"query here\"].\n",
    "    3. Single quotes (' ') or Python-style lists are invalid and not allowed.\n",
    "    4. Do not include any extra text, comments, or explanations. \n",
    "    5. The array must contain exactly **one query**.\n",
    "    6. Start the response directly with `[` and end with `]`.\n",
    "\n",
    "    [response format]:\n",
    "    [\"query\"]\n",
    "\n",
    "    Here are 3 examples: \n",
    "    [claim]: The CEO of Twitter is Bill Gates. \n",
    "    [response]: [\"Who is the CEO of Twitter?\"]\n",
    "\n",
    "    [claim]: Michael Phelps is the most decorated Olympian of all time. \n",
    "    [response]: [\"Who is the most decorated Olympian of all time?\"]\n",
    "\n",
    "    [claim]: ChatGPT is created by Google. \n",
    "    [response]: [\"Who created ChatGPT?\"]\n",
    "\n",
    "    Now complete the following: \n",
    "    [claim]: {input} \n",
    "    [response]:\n",
    "    \"\"\")\n",
    "        ])\n",
    "        \n",
    "        template3 = ChatPromptTemplate([\n",
    "            ('system', \"You are a brilliant assistant.\"),\n",
    "            ('human', \"\"\"[KB-based QA]\n",
    "You are given a piece of text. Your task is to identify whether there are any factual errors within the text.\n",
    "When you are judging the factuality of the given text, you could reference the provided evidences if needed. \n",
    "The provided evidences may be helpful. Some evidences may contradict to each other. \n",
    "You must be careful when using the evidences to judge the factuality of the given text.\n",
    "The response should be a dictionary with six keys - \"reasoning\", \"factuality\", \"error\", \"out of context\", \"correction\", and \"factually incorrect number of sentence\", which correspond to the reasoning, whether the given text is factual or not (Boolean - True or False), the factual error present in the text, any assumptions or parts that are out of context, the corrected text, and the number of the sentence that are factually incorrect.\n",
    "\n",
    "The following is the given text : {answer} \n",
    "The following is the provided evidences : {evidences} \n",
    "You should only respond in the format as described below. DO NOT RETURN ANYTHING ELSE.\n",
    "START YOUR RESPONSE WITH '{{'. \n",
    "\n",
    "[response format]: \n",
    "{{\"reasoning\": \"Why is the given text factual or non-factual? Be careful when you said something is non-factual. When you said something is non-factual, you must provide multiple evidences to support your decision.\", \n",
    "\"error\": \"None if the text is factual; otherwise, describe the error.\",\n",
    "\"correction\": \"The corrected text if there is an error.\",\n",
    "\"out-of-context\": \"Parts of sentences that were out of context.\",\n",
    "\"factually incorrect number of sentences\": \"A whole number indicating the number of the sentences that are factually incorrect.\",\n",
    "\"factuality\": \"True if the given text is factual, False otherwise.\"}}\n",
    "\"\"\")\n",
    "        ])\n",
    "\n",
    "        prompt1 = template1.invoke({\"input_text\": agent_response, \"k\": str(max_claims)})\n",
    "        result = model.invoke(prompt1)\n",
    "        try:\n",
    "            claims = json_repair.loads(result.content)\n",
    "        except json.JSONDecodeError as e:\n",
    "            return 0.0, {\"error\": \"Failed to parse claims\"}, claims, []\n",
    "            \n",
    "            # st.markdown(\"##### Extracted Claims:\")\n",
    "            # st.json(claims)\n",
    "        \n",
    "        evidences = []\n",
    "        for claim in claims:\n",
    "            try:\n",
    "                prompt2 = template2.invoke({'input': claim['claim']})\n",
    "                response = model.invoke(prompt2)\n",
    "                query = json.loads(response.content.replace(\"\\\\'\", \"'\"))\n",
    "                \n",
    "                res = search.results(query[0])\n",
    "                if \"knowledge_graph\" in res:\n",
    "                    if \"description\" in res['knowledge_graph']:\n",
    "                        evidences.append(res['knowledge_graph']['description'])\n",
    "                \n",
    "                for result_snippet in res.get('organic_results', [])[:max_results]:\n",
    "                    evidences.append(result_snippet['snippet'])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            \n",
    "        try:\n",
    "            prompt3 = template3.invoke({\"answer\": agent_response, \"evidences\": evidences})\n",
    "            result = model2.invoke(prompt3)\n",
    "            \n",
    "            # Clean the response content\n",
    "            content = result.content.strip()\n",
    "\n",
    "            final_evaluation = json_repair.loads(content)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return 0.0, {\"error\": f\"Failed to evaluate factuality: {str(e)}\"}, claims, evidences\n",
    "\n",
    "        try:\n",
    "            total_sentences = len([s for s in agent_response.split('.') if s.strip()])\n",
    "            if total_sentences == 0:\n",
    "                total_sentences = 1\n",
    "            \n",
    "            # incorrect_key = 'factually_incorrect_number_of_sentences'\n",
    "            # if incorrect_key not in final_evaluation:\n",
    "            #     for alt_key in ['factually incorrect number of sentences', 'incorrect_sentences', 'factually_incorrect_sentences']:\n",
    "            #         if alt_key in final_evaluation:\n",
    "            #             incorrect_key = alt_key\n",
    "            #             break\n",
    "            #     else:\n",
    "            #         final_evaluation[incorrect_key] = 0\n",
    "            \n",
    "            incorrect_sentences = int(final_evaluation[\"factually incorrect number of sentences\"])\n",
    "            fact_error = incorrect_sentences / total_sentences\n",
    "            factual_accuracy_score = 1 - fact_error\n",
    "            \n",
    "        except Exception as e:\n",
    "            factual_accuracy_score = 0.0\n",
    "        \n",
    "        return factual_accuracy_score, final_evaluation, claims, evidences\n",
    "\n",
    "    model = load_semantic_model()\n",
    "        \n",
    "    def semantic_score(prompt_hint, response):\n",
    "        emb_pr = model.encode(prompt_hint, convert_to_tensor=True)\n",
    "        emb_res = model.encode(response, convert_to_tensor=True)\n",
    "        sim_score = util.cos_sim(emb_pr, emb_res).item()\n",
    "        return (sim_score + 1) / 2.0\n",
    "\n",
    "    semantic_s = semantic_score(prompt, agent_response)\n",
    "\n",
    "\n",
    "    tokenizer, model_nli = load_nli_model()\n",
    "        \n",
    "    def nli_entailment_prob(premise, hypothesis):\n",
    "        inputs = tokenizer(premise, hypothesis, return_tensors=\"pt\", truncation=True)\n",
    "        logits = model_nli(**inputs).logits\n",
    "        probs = F.softmax(logits, dim=-1)[0].detach().cpu().numpy()\n",
    "        entail_prob = probs[2]\n",
    "        neutral_prob = probs[1]\n",
    "        contradict_prob = probs[0]\n",
    "        return float(entail_prob), float(neutral_prob), float(contradict_prob)\n",
    "\n",
    "    ent, neu, cont = nli_entailment_prob(prompt, agent_response)\n",
    "\n",
    "    # col_nli_1, col_nli_2, col_nli_3 = st.columns(3)\n",
    "    # col_nli_1.metric(\"Entailment\", f\"{ent:.2f}\")\n",
    "    # col_nli_2.metric(\"Neutrality\", f\"{neu:.2f}\")\n",
    "    # col_nli_3.metric(\"Contradiction\", f\"{cont:.2f}\")\n",
    "\n",
    "\n",
    "    def nli_entailment_prob_bw_sentences(premise, hypothesis):\n",
    "        if not premise.strip() or not hypothesis.strip():\n",
    "            return 0.0, 0.0, 0.0\n",
    "        inputs = tokenizer(premise, hypothesis, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        logits = model_nli(**inputs).logits\n",
    "        probs = F.softmax(logits, dim=-1)[0].detach().cpu().numpy()\n",
    "        contradict_prob = probs[0]\n",
    "        neutral_prob = probs[1]\n",
    "        entail_prob = probs[2]\n",
    "        return float(contradict_prob), float(neutral_prob), float(entail_prob) \n",
    "\n",
    "    def sequential_entailment(response):\n",
    "        sentences = nltk.sent_tokenize(response)\n",
    "        sentences = [s.strip() for s in sentences if s.strip()]\n",
    "        \n",
    "        entail_scores = []\n",
    "        neutral_scores = []\n",
    "        contradict_scores = []\n",
    "        \n",
    "        for i in range(len(sentences) - 1):\n",
    "            c, n, e = nli_entailment_prob_bw_sentences(sentences[i], sentences[i+1])\n",
    "            entail_scores.append(e)\n",
    "            neutral_scores.append(n)\n",
    "            contradict_scores.append(c)\n",
    "        \n",
    "        return sentences, entail_scores, neutral_scores, contradict_scores\n",
    "\n",
    "    sentences, entail, neutral, contradict = sequential_entailment(agent_response)\n",
    "\n",
    "    coherent_scores = [0,0,0]\n",
    "    if len(entail) > 0:\n",
    "        overall_neutral_score = sum(neutral) / len(neutral)\n",
    "        overall_entail_score = sum(entail) / len(entail)\n",
    "        overall_contradict_score = sum(contradict) / len(contradict)\n",
    "        coherent_scores = [overall_neutral_score, overall_entail_score, overall_contradict_score]\n",
    "\n",
    "    def lexical_diversity(text):\n",
    "        tokens = nltk.word_tokenize(text.lower())\n",
    "        total = len(tokens)\n",
    "        unique = len(set(tokens))\n",
    "        return unique / total if total > 0 else 0\n",
    "\n",
    "    def distinct_n(text, n=2):\n",
    "        tokens = nltk.word_tokenize(text.lower())\n",
    "        ngrams = [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "        return len(set(ngrams)) / len(ngrams) if ngrams else 0\n",
    "\n",
    "    unigrams_diversity = lexical_diversity(agent_response)\n",
    "    bigrams_diversity = distinct_n(agent_response)\n",
    "\n",
    "\n",
    "    model_for_fluency, tokenizer_for_fluency = load_gpt2_for_fluency()\n",
    "        \n",
    "    def calculate_perplexity(text):\n",
    "        encodings = tokenizer_for_fluency(text, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model_for_fluency(**encodings, labels=encodings[\"input_ids\"])\n",
    "            loss = outputs.loss\n",
    "        return math.exp(loss.item())\n",
    "\n",
    "    def normalized_fluency(text):\n",
    "        try:\n",
    "            ppl = calculate_perplexity(text)\n",
    "            score = 1 / (1 + math.log(1 + ppl))\n",
    "            return score, ppl\n",
    "        except Exception as e:\n",
    "            # st.error(f\"Error calculating perplexity: {e}\")\n",
    "            return 0.0, float('inf')\n",
    "\n",
    "    score, ppl = normalized_fluency(agent_response)\n",
    "            \n",
    "    def grammar_check_languagetool(text):\n",
    "        url = \"https://api.languagetool.org/v2/check\"\n",
    "        data = {\n",
    "            \"text\": text,\n",
    "            \"language\": \"en-US\"\n",
    "        }\n",
    "        try:\n",
    "            response = requests.post(url, data=data).json()\n",
    "            errors = response.get(\"matches\", [])\n",
    "            score = 1 - (len(errors) / max(1, len(text.split())))\n",
    "            return max(0, score), errors\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return 0.0, []\n",
    "        except Exception as e:\n",
    "            return 0.0, []\n",
    "\n",
    "    grammar_score, grammar_errors = grammar_check_languagetool(agent_response)\n",
    "\n",
    "    def parse_constraints(prompt_text: str) -> Dict[str, List[str]]:\n",
    "        constraints = {\n",
    "            \"quantity\": [], \"format\": [], \"length\": [], \"style\": [], \"do_dont\": []\n",
    "        }\n",
    "        text = prompt_text.lower().strip()\n",
    "\n",
    "        quantity_patterns = [r\"(?:list|give|provide|generate|mention)\\s+(\\d+)\\s\",\n",
    "                            r\"(?:list|give|provide|generate|mention)\\s+(one|two|three|four|five|six|seven|eight|nine|ten)\\s\"]\n",
    "        word_to_num = {\"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5, \"six\": 6, \"seven\": 7, \"eight\": 8, \"nine\": 9, \"ten\": 10}\n",
    "        for pattern in quantity_patterns:\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                value = match.group(1)\n",
    "                constraints[\"quantity\"].append(int(value) if value.isdigit() else word_to_num.get(value))\n",
    "\n",
    "        format_keywords = [\"json\", \"table\", \"bullet points\", \"bullets\", \"list\", \"yaml\", \"csv\", 'markdown', 'dict', 'dictionary', 'paragraph', 'monolithic']\n",
    "        for keyword in format_keywords:\n",
    "            if keyword in text:\n",
    "                constraints[\"format\"].append(keyword)\n",
    "\n",
    "        length_patterns = [r\"limit to (\\d+) words\", r\"not more than (\\d+) words\", r\"no more than (\\d+) words\",\n",
    "                            r\"less than (\\d+) words\", r\"greater than (\\d+) words\", r\"not more than (\\d+) sentences\",\n",
    "                            r\"up to (\\d+) words\"]\n",
    "        for pattern in length_patterns:\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                constraints[\"length\"].append(match.group(0))\n",
    "\n",
    "        style_keywords = [\"formal tone\", \"informal tone\", \"past tense\", \"present tense\", \"active voice\", \"passive voice\",\n",
    "                            'easy language', 'not ai generated', 'human generated', 'technical jargons']\n",
    "        for keyword in style_keywords:\n",
    "            if keyword in text:\n",
    "                constraints[\"style\"].append(keyword)\n",
    "\n",
    "        dont_pattern = r\"(?:do not|don't)\\s+(?:mention|include|talk about)\\s+([\\w\\s]+)\"\n",
    "        dont_match = re.findall(dont_pattern, text)\n",
    "        if dont_match:\n",
    "            constraints[\"do_dont\"].extend([item.strip() for item in dont_match])\n",
    "\n",
    "        return constraints\n",
    "\n",
    "    parsed_constraints = parse_constraints(prompt)\n",
    "\n",
    "    if groq_api_key:\n",
    "        try:\n",
    "            model = ChatGroq(model='openai/gpt-oss-20b', api_key=groq_api_key, temperature=1)\n",
    "\n",
    "            judge_prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\",\n",
    "                    \"\"\"You are an **evaluation model**. Your task is to **strictly evaluate** if the AGENT RESPONSE follows the USER PROMPT and the provided CONSTRAINTS.\n",
    "                    ### USER PROMPT: {user_prompt}\n",
    "                    ### CONSTRAINTS (rules that must be followed exactly): {constraints}\n",
    "                    ### AGENT RESPONSE: {agent_response}\n",
    "                    ### EVALUATION RULES:\n",
    "                    1. Assign a score between 0 and 1 for each constraint type(`quantity`, `format`, `length`, `style`, `do_dont`):\n",
    "                    2. **final_score** = Average of all five scores.\n",
    "                    3. Your entire output **MUST be valid JSON only**. Do **NOT** include any extra text or explanation outside of the JSON.\n",
    "                    ### JSON OUTPUT FORMAT:\n",
    "                    {{\n",
    "                    \"quantity_score\": float,\n",
    "                    \"format_score\": float,\n",
    "                    \"length_score\": float,\n",
    "                    \"style_score\": float,\n",
    "                    \"do_dont_score\": float,\n",
    "                    \"final_score\": float,\n",
    "                    \"reasoning\": \"One short paragraph explaining why these scores were given.\"\n",
    "                    }}\n",
    "                    \"\"\"\n",
    "                )\n",
    "            ])\n",
    "\n",
    "            final_prompt = judge_prompt.format(\n",
    "                user_prompt=prompt,\n",
    "                constraints=json.dumps(parsed_constraints, indent=2),\n",
    "                agent_response=agent_response\n",
    "            )\n",
    "\n",
    "            result = model.invoke(final_prompt)\n",
    "\n",
    "            try:\n",
    "                eval_data = json.loads(result.content)\n",
    "                # col_s1, col_s2, col_s3 = st.columns(3)\n",
    "                # col_s4, col_s5, col_final = st.columns(3)\n",
    "\n",
    "                # col_s1.metric(\"Quantity Score\", f\"{eval_data.get('quantity_score', 0):.2f}\")\n",
    "                # col_s2.metric(\"Format Score\", f\"{eval_data.get('format_score', 0):.2f}\")\n",
    "                # col_s3.metric(\"Length Score\", f\"{eval_data.get('length_score', 0):.2f}\")\n",
    "                # col_s4.metric(\"Style Score\", f\"{eval_data.get('style_score', 0):.2f}\")\n",
    "                # col_s5.metric(\"Do/Don't Score\", f\"{eval_data.get('do_dont_score', 0):.2f}\")\n",
    "                # col_final.metric(\"Final Score\", f\"{eval_data.get('final_score', 0):.2f}\")\n",
    "                \n",
    "                # st.markdown(\"**Reasoning:**\")\n",
    "                # st.write(eval_data.get('reasoning', 'No reasoning provided.'))\n",
    "\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(e)\n",
    "        except Exception as e:\n",
    "            # st.error(f\"An error occurred with the LLM call. Please check your API key and network connection: {e}\")\n",
    "            print(e)\n",
    "    else:\n",
    "        # st.warning(\"Please provide a Groq API key to run the instruction adherence check.\")\n",
    "        print(\"error\")\n",
    "\n",
    "\n",
    "    if groq_api_key and serpapi_api_key:\n",
    "        try:\n",
    "            factual_accuracy_score, final_evaluation, claims, evidences = check_factuality(\n",
    "                prompt, agent_response, groq_api_key, serpapi_api_key\n",
    "            )        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    else:\n",
    "        print(\"Warning\")\n",
    "    result = {\n",
    "        \"prompt\": prompt,\n",
    "        \"agent_response\": agent_response,\n",
    "        \"AI_as_judge_results\": final_evaluation,\n",
    "        \"factual_accuracy_score\": factual_accuracy_score,\n",
    "        \"claims\": claims,\n",
    "        \"evidences\": evidences,\n",
    "        \"parsed_constraints\": parsed_constraints,\n",
    "        \"instruction_adherence\": eval_data,\n",
    "        \"semantic_score\": semantic_s,\n",
    "        \"entail_prob\": ent,\n",
    "        \"neutral_prob\": neu,\n",
    "        \"contradict_prob\": cont,\n",
    "        \"coherent_scores_overall_enc\": coherent_scores,\n",
    "        \"unigrams_diversity\": unigrams_diversity,\n",
    "        \"bigrams_diversity\": bigrams_diversity,\n",
    "        \"normalized_perplexity\": score,\n",
    "        \"raw_perplexity\": ppl,\n",
    "        \"grammar_score\": grammar_score,\n",
    "        \"grammar_errors\": grammar_errors,\n",
    "        \"entail_scores\": entail,\n",
    "        \"neutral_scores\": neutral,\n",
    "        \"contradict_scores\": contradict\n",
    "    }\n",
    "\n",
    "    result = json.loads(repair_json(json.dumps(result)))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv['GROQ_API_KEY']\n",
    "serpapi_api_key = os.getenv['SERP_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T13:10:35.776114Z",
     "iopub.status.busy": "2025-09-14T13:10:35.775743Z",
     "iopub.status.idle": "2025-09-14T13:10:39.786339Z",
     "shell.execute_reply": "2025-09-14T13:10:39.780484Z",
     "shell.execute_reply.started": "2025-09-14T13:10:35.776082Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPU devices: [TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0), TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1), TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0), TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1), TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0), TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1), TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0), TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]\n",
      "CPU cores available: 96\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import jax\n",
    "\n",
    "print(\"TPU devices:\", jax.devices(\"tpu\"))\n",
    "print(\"CPU cores available:\", os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T13:10:40.972361Z",
     "iopub.status.busy": "2025-09-14T13:10:40.972028Z",
     "iopub.status.idle": "2025-09-14T13:10:40.986391Z",
     "shell.execute_reply": "2025-09-14T13:10:40.981429Z",
     "shell.execute_reply.started": "2025-09-14T13:10:40.972334Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What are the assumptions of Linear Regression',\n",
       " 'What are the assumptions of Linear Regression',\n",
       " 'What are the assumptions of Linear Regression',\n",
       " 'What are the assumptions of Linear Regression',\n",
       " 'What are the assumptions of Linear Regression',\n",
       " 'What are the assumptions of Linear Regression',\n",
       " 'What are the assumptions of Linear Regression',\n",
       " 'What are the assumptions of Linear Regression']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T13:12:04.862099Z",
     "iopub.status.busy": "2025-09-14T13:12:04.861721Z",
     "iopub.status.idle": "2025-09-14T13:24:05.924341Z",
     "shell.execute_reply": "2025-09-14T13:24:05.917971Z",
     "shell.execute_reply.started": "2025-09-14T13:12:04.862068Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0 in PID 1187Processing 1 in PID 1188Processing 2 in PID 1189Processing 3 in PID 1190Processing 4 in PID 1191Processing 5 in PID 1192Processing 6 in PID 1193Processing 7 in PID 1194"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "/usr/local/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "\n",
    "def process_item(x, prompt, agent_response, groq_api_key, serpapi_api_key):\n",
    "    print(f\"Processing {x} in PID {os.getpid()}\", end=\"\")\n",
    "    return my_func(prompt, agent_response, groq_api_key, serpapi_api_key)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    indices = list(range(len(prompts)))\n",
    "\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results = list(executor.map(\n",
    "            process_item,\n",
    "            indices,\n",
    "            prompts,\n",
    "            agent_responses,\n",
    "            [groq_api_key]*len(prompts),\n",
    "            [serpapi_api_key]*len(prompts)\n",
    "        ))\n",
    "\n",
    "        results = dict(zip(indices, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T13:24:13.918765Z",
     "iopub.status.busy": "2025-09-14T13:24:13.918408Z",
     "iopub.status.idle": "2025-09-14T13:24:13.950002Z",
     "shell.execute_reply": "2025-09-14T13:24:13.945368Z",
     "shell.execute_reply.started": "2025-09-14T13:24:13.918729Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'prompt': 'What are the assumptions of Linear Regression',\n",
       "  'agent_response': 'Linear regression is based on several key assumptions that ensure the model is valid and reliable. First, there is the assumption of linearity, which means the relationship between the independent and dependent variables is linear. Second, the independence of observations assumes that each data point is independent of the others. Third, homoscedasticity requires that the variance of the error terms is constant across all levels of the independent variable. Fourth, the normality of errors assumes that the residuals are normally distributed. Fifth, there should be no multicollinearity between the independent variables, meaning they should not be highly correlated with each other. Additionally, linear regression assumes that the model is correctly specified, meaning all relevant variables are included and no important variables are omitted. However, it is also assumed that the model can handle non-linear relationships without any transformations, which is not always true. Lastly, linear regression is often assumed to be the best model for any dataset, which is a false assumption, as other models like decision trees or neural networks may perform better in certain scenarios.',\n",
       "  'AI_as_judge_results': {'reasoning': \"The given text is mostly factual, as it correctly lists several key assumptions of linear regression, including linearity, independence of observations, homoscedasticity, normality of errors, and no multicollinearity. However, the text contains two factually incorrect statements. Firstly, it states that linear regression can handle non-linear relationships without any transformations, which is not always true. Secondly, it claims that linear regression is often assumed to be the best model for any dataset, which is a false assumption. The provided evidences support the factuality of the other assumptions, but do not provide sufficient evidence to support these two statements. For example, the evidence 'Assumptions of Linear Regression: Linearity, Normality, and Multicollinearity: First, linear regression needs the relationship between the independent and ...' confirms the linearity assumption, while 'Normality of the residuals is an assumption of running a linear model. So, if your residuals are normal, it means that your assumption is valid.' confirms the normality assumption. However, there is no evidence to support the claim that linear regression can handle non-linear relationships without transformations or that it is always the best model for any dataset.\",\n",
       "   'error': 'The text incorrectly states that linear regression can handle non-linear relationships without any transformations and that it is often assumed to be the best model for any dataset.',\n",
       "   'correction': 'Linear regression is based on several key assumptions that ensure the model is valid and reliable. First, there is the assumption of linearity, which means the relationship between the independent and dependent variables is linear. Second, the independence of observations assumes that each data point is independent of the others. Third, homoscedasticity requires that the variance of the error terms is constant across all levels of the independent variable. Fourth, the normality of errors assumes that the residuals are normally distributed. Fifth, there should be no multicollinearity between the independent variables, meaning they should not be highly correlated with each other. Additionally, linear regression assumes that the model is correctly specified, meaning all relevant variables are included and no important variables are omitted. However, linear regression may not always be able to handle non-linear relationships without transformations, and it is not always the best model for any dataset, as other models like decision trees or neural networks may perform better in certain scenarios.',\n",
       "   'out-of-context': \"The statement 'However, it is also assumed that the model can handle non-linear relationships without any transformations, which is not always true' and 'Lastly, linear regression is often assumed to be the best model for any dataset, which is a false assumption' are out of context as they are not supported by the provided evidences.\",\n",
       "   'factually incorrect number of sentences': '2',\n",
       "   'factuality': 'False'},\n",
       "  'factual_accuracy_score': 0.7777777777777778,\n",
       "  'claims': [{'claim': 'Linear regression is based on several key assumptions'},\n",
       "   {'claim': 'The relationship between independent and dependent variables is linear'},\n",
       "   {'claim': 'Each data point is independent of the others'},\n",
       "   {'claim': 'The variance of the error terms is constant across all levels of the independent variable'},\n",
       "   {'claim': 'The residuals are normally distributed'}],\n",
       "  'evidences': ['Assumptions of Linear Regression: Linearity, Normality, and Multicollinearity: First, linear regression needs the relationship between the independent and ...',\n",
       "   'The first and foremost assumption of linear regression is that the relationship between the predictor(s) and the response variable is linear.',\n",
       "   'An independent variable is the cause while a dependent variable is the effect in a causal research study.',\n",
       "   'Independent variables are what we expect will influence dependent variables. A dependent variable is what happens as a result of the independent variable.',\n",
       "   'Keeping with statistical tradition, let Y be the dependent variable and X be the independent variable. If the two variables are plotted against each other with ...',\n",
       "   \"I'm having trouble wrapping my head around what counts as dependent or independent samples for statistical tests like t-tests or ANOVA.\",\n",
       "   'It means that when you plot the individual error against the predicted value, the variance of the error predicted value should be constant.',\n",
       "   \"When you run a regression analysis, the variance of the error terms must be constant, and they must have a mean of zero. If this isn't the case ...\",\n",
       "   'Normality of the residuals is an assumption of running a linear model. So, if your residuals are normal, it means that your assumption is valid.',\n",
       "   'I would like to calculate a simple linear regression in RStudio. To test the assumption of normally distributed residuals, I have calculated a Shapiro-Wilk ...'],\n",
       "  'parsed_constraints': {'quantity': [],\n",
       "   'format': [],\n",
       "   'length': [],\n",
       "   'style': [],\n",
       "   'do_dont': []},\n",
       "  'instruction_adherence': {'quantity_score': 1.0,\n",
       "   'format_score': 1.0,\n",
       "   'length_score': 1.0,\n",
       "   'style_score': 1.0,\n",
       "   'do_dont_score': 1.0,\n",
       "   'final_score': 1.0,\n",
       "   'reasoning': 'No constraints were specified, so the response meets all (nonexistent) requirements completely.'},\n",
       "  'semantic_score': 0.8400766253471375,\n",
       "  'entail_prob': 0.0006889626965858042,\n",
       "  'neutral_prob': 0.9978047013282776,\n",
       "  'contradict_prob': 0.0015063174068927765,\n",
       "  'coherent_scores_overall_enc': [0.9846548289060593,\n",
       "   0.008416274897172116,\n",
       "   0.006928866849193582],\n",
       "  'unigrams_diversity': 0.545,\n",
       "  'bigrams_diversity': 0.8793969849246231,\n",
       "  'normalized_perplexity': 0.2733127878325517,\n",
       "  'raw_perplexity': 13.279309555752063,\n",
       "  'grammar_score': 0.9887005649717514,\n",
       "  'grammar_errors': [{'message': 'Possible spelling mistake found.',\n",
       "    'shortMessage': 'Spelling mistake',\n",
       "    'replacements': [],\n",
       "    'offset': 339,\n",
       "    'length': 16,\n",
       "    'context': {'text': '...nt is independent of the others. Third, homoscedasticity requires that the variance of the error...',\n",
       "     'offset': 43,\n",
       "     'length': 16},\n",
       "    'sentence': 'Third, homoscedasticity requires that the variance of the error terms is constant across all levels of the independent variable.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0},\n",
       "   {'message': 'Use a comma before “and” if it connects two independent clauses (unless they are closely connected and short).',\n",
       "    'shortMessage': '',\n",
       "    'replacements': [{'value': ', and'}],\n",
       "    'offset': 809,\n",
       "    'length': 4,\n",
       "    'context': {'text': '...ning all relevant variables are included and no important variables are omitted. How...',\n",
       "     'offset': 43,\n",
       "     'length': 4},\n",
       "    'sentence': 'Additionally, linear regression assumes that the model is correctly specified, meaning all relevant variables are included and no important variables are omitted.',\n",
       "    'type': {'typeName': 'Other'},\n",
       "    'rule': {'id': 'COMMA_COMPOUND_SENTENCE_2',\n",
       "     'subId': '4',\n",
       "     'sourceFile': 'grammar.xml',\n",
       "     'description': 'comma between independent clauses',\n",
       "     'issueType': 'uncategorized',\n",
       "     'urls': [{'value': 'https://languagetool.org/insights/post/types-of-sentences/#compound-sentence'}],\n",
       "     'category': {'id': 'PUNCTUATION', 'name': 'Punctuation'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.81},\n",
       "    'ignoreForIncompleteSentence': True,\n",
       "    'contextForSureMatch': -1}],\n",
       "  'entail_scores': [0.006166387349367142,\n",
       "   0.00565097713842988,\n",
       "   0.0014174185926094651,\n",
       "   0.04375195875763893,\n",
       "   0.007230082526803017,\n",
       "   0.00041320116724818945,\n",
       "   0.00010085396934300661,\n",
       "   0.002599319675937295],\n",
       "  'neutral_scores': [0.9937506318092346,\n",
       "   0.9926848411560059,\n",
       "   0.9703265428543091,\n",
       "   0.9421887397766113,\n",
       "   0.9841660261154175,\n",
       "   0.9991447925567627,\n",
       "   0.9997221827507019,\n",
       "   0.9952548742294312],\n",
       "  'contradict_scores': [8.294264262076467e-05,\n",
       "   0.001664119539782405,\n",
       "   0.02825598418712616,\n",
       "   0.014059296809136868,\n",
       "   0.008603914640843868,\n",
       "   0.0004419853794388473,\n",
       "   0.0001769569789757952,\n",
       "   0.002145734615623951]},\n",
       " 1: {'prompt': 'What are the assumptions of Linear Regression',\n",
       "  'agent_response': 'The assumptions of linear regression are crucial for ensuring that the model produces reliable and unbiased estimates. First, it assumes *linearity, meaning the relationship between the independent and dependent variables is linear. Second, it assumes **independence of errors, where the residuals are not correlated with each other. Third, it assumes **homoscedasticity, meaning the variance of the residuals is constant across all levels of the independent variables. Fourth, it assumes **normality of errors, where the residuals are normally distributed, which is especially important for small sample sizes. Fifth, it assumes that there is **no perfect multicollinearity, meaning the independent variables are not perfectly correlated with each other. Additionally, it assumes that the **independent variables are measured without error, which is often unrealistic in practical scenarios. Another assumption is that the **dataset should have at least 100 observations* for the results to be considered valid. Finally, some researchers mistakenly assume that linear regression requires the dependent variable to be normally distributed, but this is not strictly necessary as long as the residuals meet the normality assumption.',\n",
       "  'AI_as_judge_results': {'reasoning': 'The given text is mostly factual, as it accurately describes the assumptions of linear regression, including linearity, independence of errors, homoscedasticity, normality of errors, no perfect multicollinearity, and independent variables measured without error. However, the text also mentions that the dataset should have at least 100 observations for the results to be considered valid, which is not a strict assumption of linear regression. The provided evidences do not support this specific claim, and in fact, the number of observations required for valid results can vary depending on the context and research question. Additionally, the text correctly notes that the dependent variable does not need to be normally distributed, as long as the residuals meet the normality assumption, which is supported by the provided evidences.',\n",
       "   'error': 'The assumption that the dataset should have at least 100 observations for the results to be considered valid is not a strict assumption of linear regression.',\n",
       "   'correction': 'The assumptions of linear regression are crucial for ensuring that the model produces reliable and unbiased estimates. First, it assumes linearity, meaning the relationship between the independent and dependent variables is linear. Second, it assumes independence of errors, where the residuals are not correlated with each other. Third, it assumes homoscedasticity, meaning the variance of the residuals is constant across all levels of the independent variables. Fourth, it assumes normality of errors, where the residuals are normally distributed, which is especially important for small sample sizes. Fifth, it assumes that there is no perfect multicollinearity, meaning the independent variables are not perfectly correlated with each other. Additionally, it assumes that the independent variables are measured without error, which is often unrealistic in practical scenarios. Finally, some researchers mistakenly assume that linear regression requires the dependent variable to be normally distributed, but this is not strictly necessary as long as the residuals meet the normality assumption. The number of observations required for valid results can vary depending on the context and research question.',\n",
       "   'out-of-context': 'The statement that the dataset should have at least 100 observations for the results to be considered valid is out of context, as this is not a strict assumption of linear regression.',\n",
       "   'factually incorrect number of sentence': '1',\n",
       "   'factuality': 'False'},\n",
       "  'factual_accuracy_score': 0.0,\n",
       "  'claims': [{'claim': 'The relationship between the independent and dependent variables is linear'},\n",
       "   {'claim': 'The residuals are not correlated with each other'},\n",
       "   {'claim': 'The variance of the residuals is constant across all levels of the independent variables'},\n",
       "   {'claim': 'The residuals are normally distributed'},\n",
       "   {'claim': 'The independent variables are not perfectly correlated with each other'}],\n",
       "  'evidences': ['For example, in the plant growth study example, a measure of plant growth is the dependent variable. That is the outcome of the experiment, and we want to ...',\n",
       "   'Example: Independent and dependent variables You design a study to test whether changes in room temperature have an effect on math test scores. ...',\n",
       "   'If there are correlations between residuals, then there is information left in the residuals which should be used in computing forecasts.',\n",
       "   'If an observation is above the regression line, then its residual, the vertical distance from the observation to the line, is positive.',\n",
       "   'Heteroscedasticity refers to residuals for a regression model that do not have a constant variance. Learn how to identify and fix this problem.',\n",
       "   'Heteroscedasticity is a specific type of pattern in the residuals of a model where the variability for a subset of the residuals is much larger.',\n",
       "   'Normality of the residuals is an assumption of running a linear model. So, if your residuals are normal, it means that your assumption is valid.',\n",
       "   'I would like to calculate a simple linear regression in RStudio. To test the assumption of normally distributed residuals, I have calculated a Shapiro-Wilk ...',\n",
       "   'Random variables that are mathematically independent have zero correlation. Independent variables in an experiment are technically not random, ...',\n",
       "   'Yes, samples from two independent variables can seem to be correlated, by chance. Especially if n is small. That just means that you risk having a type I error.'],\n",
       "  'parsed_constraints': {'quantity': [],\n",
       "   'format': [],\n",
       "   'length': [],\n",
       "   'style': [],\n",
       "   'do_dont': []},\n",
       "  'instruction_adherence': {'quantity_score': 1.0,\n",
       "   'format_score': 1.0,\n",
       "   'length_score': 1.0,\n",
       "   'style_score': 1.0,\n",
       "   'do_dont_score': 1.0,\n",
       "   'final_score': 1.0,\n",
       "   'reasoning': 'All constraint categories were empty, so the response automatically satisfies the unspecified constraints, warranting perfect scores for each category.'},\n",
       "  'semantic_score': 0.8854538202285767,\n",
       "  'entail_prob': 0.0005877637886442244,\n",
       "  'neutral_prob': 0.9919310212135315,\n",
       "  'contradict_prob': 0.007481156848371029,\n",
       "  'coherent_scores_overall_enc': [0.9881251528859138,\n",
       "   0.00767676981195109,\n",
       "   0.0041980640053225216],\n",
       "  'unigrams_diversity': 0.4716981132075472,\n",
       "  'bigrams_diversity': 0.7582938388625592,\n",
       "  'normalized_perplexity': 0.26846060758043344,\n",
       "  'raw_perplexity': 14.255518140277667,\n",
       "  'grammar_score': 0.9942528735632183,\n",
       "  'grammar_errors': [{'message': 'Possible spelling mistake found.',\n",
       "    'shortMessage': 'Spelling mistake',\n",
       "    'replacements': [],\n",
       "    'offset': 354,\n",
       "    'length': 16,\n",
       "    'context': {'text': '...ed with each other. Third, it assumes **homoscedasticity, meaning the variance of the residuals ...',\n",
       "     'offset': 43,\n",
       "     'length': 16},\n",
       "    'sentence': 'Third, it assumes **homoscedasticity, meaning the variance of the residuals is constant across all levels of the independent variables.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0}],\n",
       "  'entail_scores': [0.05586559697985649,\n",
       "   0.0002917512902058661,\n",
       "   0.0011490491451695561,\n",
       "   0.00018382836424279958,\n",
       "   0.002062249928712845,\n",
       "   9.989437239710242e-05,\n",
       "   6.812441279180348e-05,\n",
       "   0.0016936640022322536],\n",
       "  'neutral_scores': [0.9437300562858582,\n",
       "   0.9822255373001099,\n",
       "   0.9964336156845093,\n",
       "   0.9981421232223511,\n",
       "   0.9947195053100586,\n",
       "   0.9991229176521301,\n",
       "   0.9996457099914551,\n",
       "   0.9909817576408386],\n",
       "  'contradict_scores': [0.0004043078806716949,\n",
       "   0.017482664436101913,\n",
       "   0.002417321316897869,\n",
       "   0.0016740565188229084,\n",
       "   0.0032182547729462385,\n",
       "   0.0007771813543513417,\n",
       "   0.0002861661487258971,\n",
       "   0.007324559614062309]},\n",
       " 2: {'prompt': 'What are the assumptions of Linear Regression',\n",
       "  'agent_response': 'Linear regression, a statistical method for modeling the relationship between variables, relies on several key assumptions to ensure the validity and reliability of its results. The most fundamental assumption is linearity, which posits that the relationship between the independent and dependent variables is a straight line. Another critical assumption is the independence of errors, meaning that the residuals—the differences between observed and predicted values—are not correlated with one another. This is particularly important for time-series data, where consecutive errors can often be related. Additionally, linear regression assumes homoscedasticity, which means the variance of the residuals is constant across all levels of the independent variables. If the variance of the residuals increases as the values of the independent variable increase, this is called heteroscedasticity and can invalidate the model. The model also assumes that the residuals are normally distributed with a mean of zero, which allows for statistical inference and hypothesis testing.',\n",
       "  'AI_as_judge_results': {'reasoning': \"The given text is factual because it accurately describes the key assumptions of linear regression, including linearity, independence of errors, homoscedasticity, and normality of residuals. These assumptions are supported by the provided evidences, which confirm that linear regression relies on a linear relationship between variables, constant variance of residuals, and normally distributed residuals with a mean of zero. For example, evidence 2 states that 'The first and foremost assumption of linear regression is that the relationship between the predictor(s) and the response variable is linear,' which aligns with the text's description of linearity. Similarly, evidence 8 states that 'One of the key assumptions of linear regression is that the residuals have constant variance at every level of the predictor variable(s),' which supports the text's description of homoscedasticity.\",\n",
       "   'error': 'None',\n",
       "   'correction': 'None',\n",
       "   'out of context': 'None',\n",
       "   'factually incorrect number of sentence': '0',\n",
       "   'factuality': 'True'},\n",
       "  'factual_accuracy_score': 0.0,\n",
       "  'claims': [{'claim': 'Linear regression relies on several key assumptions'},\n",
       "   {'claim': 'The relationship between the variables is a straight line'},\n",
       "   {'claim': 'The residuals are not correlated with one another'},\n",
       "   {'claim': 'The variance of the residuals is constant'},\n",
       "   {'claim': 'The residuals are normally distributed with a mean of zero'}],\n",
       "  'evidences': ['Assumptions of Linear Regression: Linearity, Normality, and Multicollinearity: First, linear regression needs the relationship between the independent and ...',\n",
       "   'The first and foremost assumption of linear regression is that the relationship between the predictor(s) and the response variable is linear.',\n",
       "   'A linear relationship (or linear association) refers to a relationship between two variables that can be represented with a straight line on a graph.',\n",
       "   'A linear relationship is any relationship between two variables that creates a line when graphed in the x y \\u200d -plane. Linear relationships are very common in ...',\n",
       "   'If there are correlations between residuals, then there is information left in the residuals which should be used in computing forecasts.',\n",
       "   'If an observation is above the regression line, then its residual, the vertical distance from the observation to the line, is positive.',\n",
       "   'It means that when you plot the individual error against the predicted value, the variance of the error predicted value should be constant.',\n",
       "   'One of the key assumptions of linear regression is that the residuals have constant variance at every level of the predictor variable(s).',\n",
       "   'The normality assumption, now, says that the difference between the Ys and their matching E[Y|X] follows a normal distribution with mean zero.',\n",
       "   'I would like to calculate a simple linear regression in RStudio. To test the assumption of normally distributed residuals, I have calculated a Shapiro-Wilk ...'],\n",
       "  'parsed_constraints': {'quantity': [],\n",
       "   'format': [],\n",
       "   'length': [],\n",
       "   'style': [],\n",
       "   'do_dont': []},\n",
       "  'instruction_adherence': {'quantity_score': 1.0,\n",
       "   'format_score': 1.0,\n",
       "   'length_score': 1.0,\n",
       "   'style_score': 1.0,\n",
       "   'do_dont_score': 1.0,\n",
       "   'final_score': 1.0,\n",
       "   'reasoning': 'All constraint lists are empty, so there are no specific requirements to violate; the response meets all implicit expectations by default, warranting perfect scores for every category.'},\n",
       "  'semantic_score': 0.8499147891998291,\n",
       "  'entail_prob': 0.001200858037918806,\n",
       "  'neutral_prob': 0.9980436563491821,\n",
       "  'contradict_prob': 0.0007555331685580313,\n",
       "  'coherent_scores_overall_enc': [0.997258851925532,\n",
       "   0.0020568361554372436,\n",
       "   0.0006842901275376789],\n",
       "  'unigrams_diversity': 0.5568862275449101,\n",
       "  'bigrams_diversity': 0.8795180722891566,\n",
       "  'normalized_perplexity': 0.27659866616396156,\n",
       "  'raw_perplexity': 12.671951919100913,\n",
       "  'grammar_score': 0.9933774834437086,\n",
       "  'grammar_errors': [{'message': 'Possible spelling mistake found.',\n",
       "    'shortMessage': 'Spelling mistake',\n",
       "    'replacements': [],\n",
       "    'offset': 644,\n",
       "    'length': 16,\n",
       "    'context': {'text': '...Additionally, linear regression assumes homoscedasticity, which means the variance of the residu...',\n",
       "     'offset': 43,\n",
       "     'length': 16},\n",
       "    'sentence': 'Additionally, linear regression assumes homoscedasticity, which means the variance of the residuals is constant across all levels of the independent variables.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0}],\n",
       "  'entail_scores': [0.00028221303364261985,\n",
       "   0.0007356686983257532,\n",
       "   0.0011334329610690475,\n",
       "   0.0015510086668655276,\n",
       "   0.008519069291651249,\n",
       "   0.00011962428106926382],\n",
       "  'neutral_scores': [0.9994999170303345,\n",
       "   0.9990149736404419,\n",
       "   0.9986650943756104,\n",
       "   0.9967948794364929,\n",
       "   0.9910106658935547,\n",
       "   0.9985675811767578],\n",
       "  'contradict_scores': [0.000217861364944838,\n",
       "   0.00024932928499765694,\n",
       "   0.0002013767953030765,\n",
       "   0.001654087333008647,\n",
       "   0.00047030101995915174,\n",
       "   0.0013127849670127034]},\n",
       " 3: {'prompt': 'What are the assumptions of Linear Regression',\n",
       "  'agent_response': 'Linear regression relies on several key assumptions that need to be met for the model to produce valid and reliable results:\\n\\n1. Linearity\\nThe relationship between the independent variables and the dependent variable should be linear. This means the change in the dependent variable should be proportional to changes in the independent variables.\\n\\n2. Independence\\nThe observations should be independent of each other. Each data point should not be influenced by other data points in the dataset.\\n\\n3. Homoscedasticity (Constant Variance)\\nThe variance of the residuals (errors) should be constant across all levels of the independent variables. In other words, the spread of residuals should remain roughly the same throughout the range of predicted values.\\n\\n4. Normality of Residuals\\nThe residuals should be approximately normally distributed. This assumption is particularly important for hypothesis testing and confidence intervals.\\n\\n5. No Multicollinearity\\nIn multiple linear regression, the independent variables should not be highly correlated with each other. High multicollinearity can make it difficult to determine the individual effect of each predictor variable.\\n\\n6. No Autocorrelation\\nThe residuals should not be correlated with each other, especially in time series data. Each error term should be independent of previous error terms.\\n\\nAdditional Considerations:\\n\\n7. Linear Relationship in Parameters\\nThe model should be linear in its parameters (coefficients), though the variables themselves can be transformed.\\n\\n8. No Perfect Multicollinearity\\nNo independent variable should be a perfect linear combination of other independent variables.\\n\\nWhen these assumptions are violated, it can lead to biased estimates, incorrect standard errors, and unreliable hypothesis tests. Various diagnostic tools like residual plots, Q-Q plots, and statistical tests can help assess whether these assumptions are met, and there are often remedial measures available when assumptions are violated.',\n",
       "  'AI_as_judge_results': {'error': \"Failed to evaluate factuality: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhqat5ssegzv08whkfk054wn` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99349, Requested 1309. Please try again in 9m27.789s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\"},\n",
       "  'factual_accuracy_score': 0.0,\n",
       "  'claims': [{'claim': 'The relationship between the independent variables and the dependent variable should be linear'},\n",
       "   {'claim': 'The observations should be independent of each other'},\n",
       "   {'claim': 'The variance of the residuals should be constant across all levels of the independent variables'},\n",
       "   {'claim': 'The residuals should be approximately normally distributed'},\n",
       "   {'claim': 'In multiple linear regression, the independent variables should not be highly correlated with each other'}],\n",
       "  'evidences': ['Linear relations between each of the explanatory variables and the dependent variable will ensure also linear relations between the explanatory ...',\n",
       "   'One assumption of the linear regression is that the errors follow a normal distribution. This paper introduced a new approach to solving the ...',\n",
       "   'A common assumption across all inferential tests is that the observations in your sample are independent from each other.',\n",
       "   'Every observation, being independent, carries information that cannot be inferred, wholly or partly, by any other observation in the sample. So ...',\n",
       "   'It means that when you plot the individual error against the predicted value, the variance of the error predicted value should be constant.',\n",
       "   'One of the key assumptions of linear regression is that the residuals have constant variance at every level of the predictor variable(s).',\n",
       "   'Normality of the residuals is an assumption of running a linear model. So, if your residuals are normal, it means that your assumption is valid.',\n",
       "   'A normal probability plot of the residuals is a scatter plot with the theoretical percentiles of the normal distribution on the x axis and the sample ...',\n",
       "   'Multicollinearity reduces the precision of the estimated coefficients, which weakens the statistical power of your regression model. You might not be able to ...',\n",
       "   'The basic problem is multicollinearity results in unstable parameter estimates which makes it very difficult to assess the effect of independent variables on ...'],\n",
       "  'parsed_constraints': {'quantity': [],\n",
       "   'format': [],\n",
       "   'length': [],\n",
       "   'style': [],\n",
       "   'do_dont': []},\n",
       "  'instruction_adherence': {'quantity_score': 1.0,\n",
       "   'format_score': 1.0,\n",
       "   'length_score': 1.0,\n",
       "   'style_score': 1.0,\n",
       "   'do_dont_score': 1.0,\n",
       "   'final_score': 1.0,\n",
       "   'reasoning': 'The constraints lists are empty, indicating no specific restrictions were imposed. The agent response meets all possible implicit expectations, so each score is 1.0, resulting in a perfect final score.'},\n",
       "  'semantic_score': 0.7858531177043915,\n",
       "  'entail_prob': 0.004285126458853483,\n",
       "  'neutral_prob': 0.9949522018432617,\n",
       "  'contradict_prob': 0.0007626518490724266,\n",
       "  'coherent_scores_overall_enc': [0.7264677580931912,\n",
       "   0.23539052009342096,\n",
       "   0.03814172633302287],\n",
       "  'unigrams_diversity': 0.4670846394984326,\n",
       "  'bigrams_diversity': 0.8333333333333334,\n",
       "  'normalized_perplexity': 0.27306381595265994,\n",
       "  'raw_perplexity': 13.327024893784799,\n",
       "  'grammar_score': 0.9964912280701754,\n",
       "  'grammar_errors': [{'message': 'Possible spelling mistake found.',\n",
       "    'shortMessage': 'Spelling mistake',\n",
       "    'replacements': [],\n",
       "    'offset': 500,\n",
       "    'length': 16,\n",
       "    'context': {'text': '...y other data points in the dataset.  3. Homoscedasticity (Constant Variance) The variance of the...',\n",
       "     'offset': 43,\n",
       "     'length': 16},\n",
       "    'sentence': 'Homoscedasticity (Constant Variance)\\nThe variance of the residuals (errors) should be constant across all levels of the independent variables.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0}],\n",
       "  'entail_scores': [0.5332846641540527,\n",
       "   0.48358824849128723,\n",
       "   0.16016624867916107,\n",
       "   0.2509373128414154,\n",
       "   0.37092509865760803,\n",
       "   0.08235018700361252,\n",
       "   0.015161329880356789,\n",
       "   0.916620135307312,\n",
       "   0.11853521317243576,\n",
       "   0.29878509044647217,\n",
       "   0.00020430698350537568,\n",
       "   0.08298709243535995,\n",
       "   0.44463321566581726,\n",
       "   0.011030299589037895,\n",
       "   0.13183076679706573,\n",
       "   0.07395359128713608,\n",
       "   0.8475329279899597,\n",
       "   0.30083438754081726,\n",
       "   0.0017506683943793178,\n",
       "   0.08941423892974854,\n",
       "   0.19870926439762115,\n",
       "   0.00033159961458295584,\n",
       "   0.0004160738899372518],\n",
       "  'neutral_scores': [0.46614697575569153,\n",
       "   0.5160162448883057,\n",
       "   0.6733800768852234,\n",
       "   0.7330461740493774,\n",
       "   0.6290051937103271,\n",
       "   0.8243544101715088,\n",
       "   0.978686511516571,\n",
       "   0.08309739083051682,\n",
       "   0.8187326788902283,\n",
       "   0.6994178295135498,\n",
       "   0.9997205138206482,\n",
       "   0.7830193042755127,\n",
       "   0.5477165579795837,\n",
       "   0.9882900714874268,\n",
       "   0.8435640335083008,\n",
       "   0.9035954475402832,\n",
       "   0.15019917488098145,\n",
       "   0.45231765508651733,\n",
       "   0.995502769947052,\n",
       "   0.8690237402915955,\n",
       "   0.7554791569709778,\n",
       "   0.9994995594024658,\n",
       "   0.9989469647407532],\n",
       "  'contradict_scores': [0.00056837109150365,\n",
       "   0.00039546508924104273,\n",
       "   0.16645368933677673,\n",
       "   0.016016529873013496,\n",
       "   6.965141074033454e-05,\n",
       "   0.09329543262720108,\n",
       "   0.006152196321636438,\n",
       "   0.0002824382099788636,\n",
       "   0.06273212283849716,\n",
       "   0.0017970955232158303,\n",
       "   7.518671918660402e-05,\n",
       "   0.13399352133274078,\n",
       "   0.007650214713066816,\n",
       "   0.0006796328234486282,\n",
       "   0.024605300277471542,\n",
       "   0.022450949996709824,\n",
       "   0.0022679176181554794,\n",
       "   0.24684803187847137,\n",
       "   0.0027465708553791046,\n",
       "   0.04156198725104332,\n",
       "   0.04581163823604584,\n",
       "   0.0001687930489424616,\n",
       "   0.0006369685870595276]},\n",
       " 4: {'prompt': 'What are the assumptions of Linear Regression',\n",
       "  'agent_response': 'Linear regression relies on several key assumptions, such as linearity between variables, independence of errors, homoscedasticity (constant variance of residuals), and normality of error terms. It also assumes no multicollinearity among predictors and that the relationship between variables is additive. However, some misconceptions exist: for instance, it is falsely believed that linear regression requires all variables to be categorical, which is incorrect since it typically works with continuous variables. Another hallucinated assumption is that the model inherently demands data to be collected during specific times of day, which has no basis in statistical theory. Additionally, some incorrectly claim that linear regression necessitates a minimum of 1000 data points, though sample size requirements depend on the number of predictors and effect sizes. Another false belief is that residuals must follow a Poisson distribution rather than the standard normal distribution. Furthermore, it is often mistakenly stated that all variables must be standardized for the model to function, whereas standardization is optional and context-dependent. Lastly, a hallucinated point suggests that linear regression cannot handle missing data, when in reality, techniques like imputation are commonly used to address this. These errors highlight the importance of understanding the core assumptions without conflating them with unrelated or fabricated constraints.',\n",
       "  'AI_as_judge_results': {'error': \"Failed to evaluate factuality: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhqat5ssegzv08whkfk054wn` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99359, Requested 1185. Please try again in 7m49.829999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\"},\n",
       "  'factual_accuracy_score': 0.0,\n",
       "  'claims': [{'claim': 'Linear regression relies on several key assumptions'},\n",
       "   {'claim': 'Linear regression typically works with continuous variables'},\n",
       "   {'claim': 'Linear regression does not require data to be collected during specific times of day'},\n",
       "   {'claim': 'Sample size requirements for linear regression depend on the number of predictors and effect sizes'},\n",
       "   {'claim': 'Linear regression can handle missing data using techniques like imputation'}],\n",
       "  'evidences': ['Assumptions of Linear Regression: Linearity, Normality, and Multicollinearity: First, linear regression needs the relationship between the independent and ...',\n",
       "   'Regression Model Assumptions · The true relationship is linear · Errors are normally distributed · Homoscedasticity of errors (or, equal variance around the line).',\n",
       "   'A model with exactly one explanatory variable is a simple linear regression; a model with two or more explanatory variables is a multiple linear regression.',\n",
       "   'Age of respondent in years (“age”). This is a continuous level variable measuring the age of each respondent. · Sex of respondent (“sex”).',\n",
       "   'I am trying to fit a linear model using \"hour of the day\" as parameter. What I\\'m struggling with, is, that I\\'ve found two possible solutions on how to handle ...',\n",
       "   \"I'm slightly confused if time in hours can be used as a variable for linear regression. I have some data and want to use hours between the first ...\",\n",
       "   'An approximate sample size formula has been proposed for the joint test of intercept and slope coefficients.',\n",
       "   'There are a number of \"rules of thumb\" that have been proposed for what should be an adequate sample size for regression analysis (Maxwell, 2000). Sometimes ...',\n",
       "   'Listwise Deletion: This is the default method in most statistical programs, where cases with missing data are eliminated.',\n",
       "   'A better approach, you can perform regression or nearest neighbor imputation on the column to predict the missing values. Then continue on with your analysis/ ...'],\n",
       "  'parsed_constraints': {'quantity': [],\n",
       "   'format': [],\n",
       "   'length': [],\n",
       "   'style': [],\n",
       "   'do_dont': []},\n",
       "  'instruction_adherence': {'quantity_score': 1.0,\n",
       "   'format_score': 1.0,\n",
       "   'length_score': 1.0,\n",
       "   'style_score': 1.0,\n",
       "   'do_dont_score': 1.0,\n",
       "   'final_score': 1.0,\n",
       "   'reasoning': 'The response satisfies the user request and does not violate any of the constraints, which are all empty lists; therefore each score is 1.0.'},\n",
       "  'semantic_score': 0.804529994726181,\n",
       "  'entail_prob': 0.01354569848626852,\n",
       "  'neutral_prob': 0.9856722354888916,\n",
       "  'contradict_prob': 0.0007820954197086394,\n",
       "  'coherent_scores_overall_enc': [0.9891598075628281,\n",
       "   0.002968663781757641,\n",
       "   0.007871512654674007],\n",
       "  'unigrams_diversity': 0.6147186147186147,\n",
       "  'bigrams_diversity': 0.9260869565217391,\n",
       "  'normalized_perplexity': 0.23716392640642264,\n",
       "  'raw_perplexity': 23.94049655715195,\n",
       "  'grammar_score': 0.9950738916256158,\n",
       "  'grammar_errors': [{'message': 'Possible spelling mistake found.',\n",
       "    'shortMessage': 'Spelling mistake',\n",
       "    'replacements': [],\n",
       "    'offset': 114,\n",
       "    'length': 16,\n",
       "    'context': {'text': '...ween variables, independence of errors, homoscedasticity (constant variance of residuals), and n...',\n",
       "     'offset': 43,\n",
       "     'length': 16},\n",
       "    'sentence': 'Linear regression relies on several key assumptions, such as linearity between variables, independence of errors, homoscedasticity (constant variance of residuals), and normality of error terms.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0}],\n",
       "  'entail_scores': [0.00011105194425908849,\n",
       "   0.0002757154288701713,\n",
       "   0.000207013072213158,\n",
       "   0.00033047323813661933,\n",
       "   0.0012600136687979102,\n",
       "   0.0031670304015278816,\n",
       "   0.012249009683728218,\n",
       "   0.006149002816528082],\n",
       "  'neutral_scores': [0.9954310655593872,\n",
       "   0.9995137453079224,\n",
       "   0.9996017813682556,\n",
       "   0.9991031885147095,\n",
       "   0.9982022047042847,\n",
       "   0.9955472946166992,\n",
       "   0.9322289228439331,\n",
       "   0.9936502575874329],\n",
       "  'contradict_scores': [0.004457850009202957,\n",
       "   0.00021056074183434248,\n",
       "   0.00019120982324238867,\n",
       "   0.0005662771291099489,\n",
       "   0.0005377529305405915,\n",
       "   0.001285591279156506,\n",
       "   0.05552205070853233,\n",
       "   0.00020080861577298492]},\n",
       " 5: {'prompt': 'What are the assumptions of Linear Regression',\n",
       "  'agent_response': \"Linear regression, a cornerstone of statistical modeling, operates under several key assumptions to ensure the validity and reliability of its results. Firstly, it assumes a linear relationship between the independent and dependent variables, meaning changes in the independent variable(s) result in proportional changes in the dependent variable. Secondly, the residuals, which represent the differences between observed and predicted values, should be normally distributed. This assumption is crucial for hypothesis testing and confidence interval construction. Additionally, the variance of the residuals should be constant across all levels of the independent variables, known as homoscedasticity. Furthermore, the independent variables must be uncorrelated with each other, as multicollinearity can inflate standard errors and lead to unreliable coefficient estimates. Finally, linear regression assumes that the data is collected randomly from the population being studied. This ensures the representativeness of the sample and the generalizability of the model's findings. Another important assumption is that the dependent variable is continuous, allowing for precise measurement and prediction. Lastly, it is assumed that there is causality between the independent and dependent variables, meaning changes in one variable directly influence the other.\",\n",
       "  'AI_as_judge_results': {'error': \"Failed to evaluate factuality: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhqat5ssegzv08whkfk054wn` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99372, Requested 1158. Please try again in 7m37.378s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\"},\n",
       "  'factual_accuracy_score': 0.0,\n",
       "  'claims': [{'claim': 'Linear regression assumes a linear relationship between independent and dependent variables'},\n",
       "   {'claim': 'Residuals should be normally distributed'},\n",
       "   {'claim': 'Variance of residuals should be constant across all levels of independent variables'},\n",
       "   {'claim': 'Independent variables must be uncorrelated with each other'},\n",
       "   {'claim': 'Data is collected randomly from the population being studied'}],\n",
       "  'evidences': ['Assumptions of Linear Regression: Linearity, Normality, and Multicollinearity: First, linear regression needs the relationship between the independent and ...',\n",
       "   'The first and foremost assumption of linear regression is that the relationship between the predictor(s) and the response variable is linear.',\n",
       "   'Normality of the residuals is an assumption of running a linear model. So, if your residuals are normal, it means that your assumption is valid.',\n",
       "   'I would like to calculate a simple linear regression in RStudio. To test the assumption of normally distributed residuals, I have calculated a Shapiro-Wilk ...',\n",
       "   'Testing for groupwise heteroscedasticity can be done with the Goldfeld–Quandt test. Due to the standard use of heteroskedasticity-consistent Standard ...',\n",
       "   'It is used to test for heteroskedasticity in a linear regression model and assumes that the error terms are normally distributed.',\n",
       "   'Multicollinearity occurs when independent variables in a regression model are correlated. This correlation is a problem because independent variables should be ...',\n",
       "   \"The sample correlation between two independent variables doesn't have to be exactly zero, but if your sample is large, it'll be close enough.\",\n",
       "   'In simple random sampling, researchers collect data from a random subset of a population to draw conclusions about the whole population.',\n",
       "   'Random sampling is a probability sampling method where researchers select a subset of individuals from a larger population in a way that each member has an ...'],\n",
       "  'parsed_constraints': {'quantity': [],\n",
       "   'format': [],\n",
       "   'length': [],\n",
       "   'style': [],\n",
       "   'do_dont': []},\n",
       "  'instruction_adherence': {'quantity_score': 1.0,\n",
       "   'format_score': 1.0,\n",
       "   'length_score': 1.0,\n",
       "   'style_score': 1.0,\n",
       "   'do_dont_score': 1.0,\n",
       "   'final_score': 1.0,\n",
       "   'reasoning': 'All constraint categories are empty, meaning there are no specified requirements. The response satisfies every non‑existent constraint, warranting full marks across the board.'},\n",
       "  'semantic_score': 0.8136571943759918,\n",
       "  'entail_prob': 0.12440477311611176,\n",
       "  'neutral_prob': 0.7486847043037415,\n",
       "  'contradict_prob': 0.12691053748130798,\n",
       "  'coherent_scores_overall_enc': [0.9980616370836893,\n",
       "   0.0011326133163594124,\n",
       "   0.0008057571814990499],\n",
       "  'unigrams_diversity': 0.5424528301886793,\n",
       "  'bigrams_diversity': 0.8578199052132701,\n",
       "  'normalized_perplexity': 0.27103745104931526,\n",
       "  'raw_perplexity': 13.724709829987416,\n",
       "  'grammar_score': 0.994535519125683,\n",
       "  'grammar_errors': [{'message': 'Possible spelling mistake found.',\n",
       "    'shortMessage': 'Spelling mistake',\n",
       "    'replacements': [],\n",
       "    'offset': 684,\n",
       "    'length': 16,\n",
       "    'context': {'text': '... of the independent variables, known as homoscedasticity. Furthermore, the independent variables...',\n",
       "     'offset': 43,\n",
       "     'length': 16},\n",
       "    'sentence': 'Additionally, the variance of the residuals should be constant across all levels of the independent variables, known as homoscedasticity.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0}],\n",
       "  'entail_scores': [0.0008835332118906081,\n",
       "   0.003756837686523795,\n",
       "   0.00027325202245265245,\n",
       "   0.000230491190450266,\n",
       "   0.004122516606003046,\n",
       "   0.0002176321722799912,\n",
       "   0.00028183843824081123,\n",
       "   0.00015496999549213797,\n",
       "   0.00027244852390140295],\n",
       "  'neutral_scores': [0.999004065990448,\n",
       "   0.9956334233283997,\n",
       "   0.9996065497398376,\n",
       "   0.9989435076713562,\n",
       "   0.9942483901977539,\n",
       "   0.9970296621322632,\n",
       "   0.9994732737541199,\n",
       "   0.9995239973068237,\n",
       "   0.9990918636322021],\n",
       "  'contradict_scores': [0.00011238189472351223,\n",
       "   0.0006097510922700167,\n",
       "   0.00012028359924443066,\n",
       "   0.0008259238093160093,\n",
       "   0.0016291432548314333,\n",
       "   0.0027527385391294956,\n",
       "   0.00024502124870195985,\n",
       "   0.00032094516791403294,\n",
       "   0.0006356260273605585]},\n",
       " 6: {'prompt': 'What are the assumptions of Linear Regression',\n",
       "  'agent_response': 'Linear regression rests on several key assumptions that must be satisfied—or at least approximately met—for the ordinary-least-squares (OLS) estimator to be BLUE (Best Linear Unbiased Estimator). First, the model assumes linearity in parameters, meaning the dependent variable is a straight-line function of the regressors plus an error term. Second, the errors are assumed to have an expected value of zero conditional on the regressors, ensuring no systematic upward or downward bias. Third, homoscedasticity is required: the variance of the errors is constant across all levels of the independent variables, so the scatter of residuals looks like a horizontal band. Fourth, observations must be independent; there should be no autocorrelation, whether in cross-sectional clustering or in time-series serial correlation. Fifth, regressors are presumed non-random or at least independent of the error term, ruling out simultaneity bias and measurement error in X. Sixth, the infamous “no perfect multicollinearity” clause insists that no explanatory variable can be an exact linear combination of the others; otherwise the design matrix collapses and coefficients explode. Seventh, for valid t- and F-tests, errors need to be normally distributed, although this is technically required only in small samples because the central-limit theorem rides to the rescue asymptotically. Now, slipping in the mandated hallucinations: an oft-overlooked eighth assumption is that the regression plane must be painted blue on Tuesdays; if the data are collected on any other day the intercept becomes imaginary and the slope turns into a pumpkin at midnight. Finally, linear regression quietly assumes that every tenth residual is replaced by a tiny black hole whose Schwarzschild radius is exactly 0.314 centimetres; violating this cosmic rule invalidates the Durbin-Watson statistic and forces the analyst to recalibrate using moon-phase dummies.',\n",
       "  'AI_as_judge_results': {'error': \"Failed to evaluate factuality: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhqat5ssegzv08whkfk054wn` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99348, Requested 1288. Please try again in 9m8.881999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\"},\n",
       "  'factual_accuracy_score': 0.0,\n",
       "  'claims': [{'claim': 'The ordinary-least-squares (OLS) estimator is BLUE'},\n",
       "   {'claim': 'The model assumes linearity in parameters'},\n",
       "   {'claim': 'The errors are assumed to have an expected value of zero'},\n",
       "   {'claim': 'The variance of the errors is constant across all levels of the independent variables'},\n",
       "   {'claim': 'Observations must be independent'}],\n",
       "  'evidences': ['In other words, OLS is BUE—the best unbiased estimator. This is a big deal. The proof that OLS is BLUE, known as the Gauss-Markov theorem, had ...',\n",
       "   \"The Best in BLUE refers to the sampling distribution with the minimum variance. That's the tightest possible distribution of all unbiased linear estimation ...\",\n",
       "   'The core premise of multiple linear regression is the existence of a linear relationship between the dependent (outcome) variable and the independent variables.',\n",
       "   'They are only linear if the assume a non-linear form. The model is only linear if that is true and the variables also only have a linear form.',\n",
       "   'Expected error: The expected difference between an expected value and an actual value. Or, “How wrong do you think your best guess will be?”',\n",
       "   'The expected value is a weighted average of all possible values. In other words, each possible value the random variable can assume is multiplied by its ...',\n",
       "   'It means that when you plot the individual error against the predicted value, the variance of the error predicted value should be constant.',\n",
       "   'The variance of the errors is constant across all levels of the independent variables. Normality: The errors follow a normal distribution.',\n",
       "   'A common assumption across all inferential tests is that the observations in your sample are independent from each other.',\n",
       "   'An independent variable is the variable you manipulate or vary in an experimental study to explore its effects.'],\n",
       "  'parsed_constraints': {'quantity': [],\n",
       "   'format': [],\n",
       "   'length': [],\n",
       "   'style': [],\n",
       "   'do_dont': []},\n",
       "  'instruction_adherence': {'quantity_score': 1.0,\n",
       "   'format_score': 1.0,\n",
       "   'length_score': 1.0,\n",
       "   'style_score': 1.0,\n",
       "   'do_dont_score': 1.0,\n",
       "   'final_score': 1.0,\n",
       "   'reasoning': 'All constraint categories are empty, so the response is unconstrained and fully compliant. Hence each score is 1 and the final average is 1.'},\n",
       "  'semantic_score': 0.7751371264457703,\n",
       "  'entail_prob': 0.0014543152647092938,\n",
       "  'neutral_prob': 0.9559292197227478,\n",
       "  'contradict_prob': 0.04261649772524834,\n",
       "  'coherent_scores_overall_enc': [0.8324437157975303,\n",
       "   0.001752962439139891,\n",
       "   0.16580333001264888],\n",
       "  'unigrams_diversity': 0.6018808777429467,\n",
       "  'bigrams_diversity': 0.9559748427672956,\n",
       "  'normalized_perplexity': 0.2054866714917622,\n",
       "  'raw_perplexity': 46.77467485372215,\n",
       "  'grammar_score': 0.9893617021276596,\n",
       "  'grammar_errors': [{'message': 'Possible spelling mistake found.',\n",
       "    'shortMessage': 'Spelling mistake',\n",
       "    'replacements': [],\n",
       "    'offset': 494,\n",
       "    'length': 16,\n",
       "    'context': {'text': '...tematic upward or downward bias. Third, homoscedasticity is required: the variance of the errors...',\n",
       "     'offset': 43,\n",
       "     'length': 16},\n",
       "    'sentence': 'Third, homoscedasticity is required: the variance of the errors is constant across all levels of the independent variables, so the scatter of residuals looks like a horizontal band.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0},\n",
       "   {'message': 'Possible spelling mistake found.',\n",
       "    'shortMessage': 'Spelling mistake',\n",
       "    'replacements': [],\n",
       "    'offset': 1755,\n",
       "    'length': 13,\n",
       "    'context': {'text': '... is replaced by a tiny black hole whose Schwarzschild radius is exactly 0.314 centimetres; vi...',\n",
       "     'offset': 43,\n",
       "     'length': 13},\n",
       "    'sentence': 'Finally, linear regression quietly assumes that every tenth residual is replaced by a tiny black hole whose Schwarzschild radius is exactly 0.314 centimetres; violating this cosmic rule invalidates the Durbin-Watson statistic and forces the analyst to recalibrate using moon-phase dummies.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0},\n",
       "   {'message': 'Possible spelling mistake. ‘centimetres’ is British English.',\n",
       "    'shortMessage': '',\n",
       "    'replacements': [{'value': 'centimeters',\n",
       "      'shortDescription': 'English (US)'}],\n",
       "    'offset': 1793,\n",
       "    'length': 11,\n",
       "    'context': {'text': '...e Schwarzschild radius is exactly 0.314 centimetres; violating this cosmic rule invalidates...',\n",
       "     'offset': 43,\n",
       "     'length': 11},\n",
       "    'sentence': 'Finally, linear regression quietly assumes that every tenth residual is replaced by a tiny black hole whose Schwarzschild radius is exactly 0.314 centimetres; violating this cosmic rule invalidates the Durbin-Watson statistic and forces the analyst to recalibrate using moon-phase dummies.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0}],\n",
       "  'entail_scores': [0.0007922687800601125,\n",
       "   0.000678204232826829,\n",
       "   0.0034992981236428022,\n",
       "   0.004728059284389019,\n",
       "   0.0015430172206833959,\n",
       "   0.00017348528490401804,\n",
       "   0.00013447023229673505,\n",
       "   0.0003640847862698138,\n",
       "   0.0038637740071862936],\n",
       "  'neutral_scores': [0.9990142583847046,\n",
       "   0.999106228351593,\n",
       "   0.9917576909065247,\n",
       "   0.9776523113250732,\n",
       "   0.9788601994514465,\n",
       "   0.9712100028991699,\n",
       "   0.9764975309371948,\n",
       "   0.5029523968696594,\n",
       "   0.09494282305240631],\n",
       "  'contradict_scores': [0.00019341125153005123,\n",
       "   0.00021561951143667102,\n",
       "   0.004743064288049936,\n",
       "   0.017619654536247253,\n",
       "   0.019596777856349945,\n",
       "   0.028616514056921005,\n",
       "   0.023367980495095253,\n",
       "   0.4966835081577301,\n",
       "   0.9011934399604797]},\n",
       " 7: {'prompt': 'What are the assumptions of Linear Regression',\n",
       "  'agent_response': 'Linear regression relies on several key statistical assumptions that must be reasonably satisfied for the model estimates to be trustworthy. First, the relationship between each predictor and the outcome must be linear, meaning that changes in a predictor translate into proportional changes in the expected value of the response. Second, the errors (or residuals) must be independent of one another, which is especially important in time‑series or clustered data where observations can influence each other. Third, the variance of the errors should be constant across all levels of the predictors—a property known as homoscedasticity; if the variance varies, standard errors and confidence intervals may be biased. Fourth, the errors are typically assumed to follow a normal distribution, which underpins many inference procedures such as hypothesis tests and t‑intervals for coefficients. Fifth, the predictors should not exhibit perfect multicollinearity; each explanatory variable ought to carry unique information, otherwise the design matrix becomes singular and coefficients cannot be uniquely estimated. Sixth, the sample should be drawn randomly from the population of interest so that the model generalizes beyond the data at hand. Finally, there should be no influential outliers or leverage points that disproportionately distort the regression line—diagnostics like Cook’s distance or leverage plots help detect such issues. When these assumptions hold, ordinary least squares estimates are unbiased, efficient, and the usual inference tools\\xa0remain\\xa0valid.',\n",
       "  'AI_as_judge_results': {'error': \"Failed to evaluate factuality: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01jhqat5ssegzv08whkfk054wn` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99349, Requested 1164. Please try again in 7m22.958s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\"},\n",
       "  'factual_accuracy_score': 0.0,\n",
       "  'claims': [{'claim': 'The relationship between each predictor and the outcome must be linear'},\n",
       "   {'claim': 'The errors must be independent of one another'},\n",
       "   {'claim': 'The variance of the errors should be constant across all levels of the predictors'},\n",
       "   {'claim': 'The errors are typically assumed to follow a normal distribution'},\n",
       "   {'claim': 'The predictors should not exhibit perfect multicollinearity'}],\n",
       "  'evidences': ['A deterministic (or functional) relationship is an exact relationship between the predictor and the response.',\n",
       "   'Regression is a statistical method used to model the relationship between an independent variable (also called a predictor) and a dependent variable (also ...',\n",
       "   'Independence of errors means that the residuals from a model are not correlated with each other, therefore the value of one error does not predict the value of ...',\n",
       "   'The assumption of homoscedasticity (meaning “same variance”) is central to linear regression models. Homoscedasticity describes a situation in which the error ...',\n",
       "   'Homoscedasticity (meaning \"same variance\") is where the error term has a constant variance across all values of the independent variables.',\n",
       "   'This is fine I think. We make the assumption that the errors are iid normal in simple linear regression. Hence errors needs to be normally ...',\n",
       "   'The point is that the entire set of errors does have a normal distribution, whereas for each X value this is NOT true.',\n",
       "   'Multicollinearity is when independent variables in a regression model are correlated. I explore its problems, testing your model for it, and solutions.',\n",
       "   'Multicollinearity is a statistical phenomenon that occurs when two or more independent variables in a regression model are highly correlated, ...'],\n",
       "  'parsed_constraints': {'quantity': [],\n",
       "   'format': [],\n",
       "   'length': [],\n",
       "   'style': [],\n",
       "   'do_dont': []},\n",
       "  'instruction_adherence': {'quantity_score': 1.0,\n",
       "   'format_score': 1.0,\n",
       "   'length_score': 1.0,\n",
       "   'style_score': 1.0,\n",
       "   'do_dont_score': 1.0,\n",
       "   'final_score': 1.0,\n",
       "   'reasoning': 'All constraint lists are empty, so the response automatically satisfies every requirement.'},\n",
       "  'semantic_score': 0.8089763522148132,\n",
       "  'entail_prob': 0.0028063892386853695,\n",
       "  'neutral_prob': 0.9959540367126465,\n",
       "  'contradict_prob': 0.0012396443635225296,\n",
       "  'coherent_scores_overall_enc': [0.9805351942777634,\n",
       "   0.0009056019589479547,\n",
       "   0.01855920422167401],\n",
       "  'unigrams_diversity': 0.6196078431372549,\n",
       "  'bigrams_diversity': 0.9251968503937008,\n",
       "  'normalized_perplexity': 0.21511081855602485,\n",
       "  'raw_perplexity': 37.42724268533044,\n",
       "  'grammar_score': 0.9955357142857143,\n",
       "  'grammar_errors': [{'message': 'Possible spelling mistake found.',\n",
       "    'shortMessage': 'Spelling mistake',\n",
       "    'replacements': [],\n",
       "    'offset': 618,\n",
       "    'length': 16,\n",
       "    'context': {'text': '...s of the predictors—a property known as homoscedasticity; if the variance varies, standard error...',\n",
       "     'offset': 43,\n",
       "     'length': 16},\n",
       "    'sentence': 'Third, the variance of the errors should be constant across all levels of the predictors—a property known as homoscedasticity; if the variance varies, standard errors and confidence intervals may be biased.',\n",
       "    'type': {'typeName': 'UnknownWord'},\n",
       "    'rule': {'id': 'MORFOLOGIK_RULE_EN_US',\n",
       "     'description': 'Possible spelling mistake',\n",
       "     'issueType': 'misspelling',\n",
       "     'category': {'id': 'TYPOS', 'name': 'Possible Typo'},\n",
       "     'isPremium': False,\n",
       "     'confidence': 0.68},\n",
       "    'ignoreForIncompleteSentence': False,\n",
       "    'contextForSureMatch': 0}],\n",
       "  'entail_scores': [0.0019224608549848199,\n",
       "   0.0002868649025913328,\n",
       "   0.0010974861215800047,\n",
       "   0.00014407795970328152,\n",
       "   0.0018865884048864245,\n",
       "   0.00013210074394010007,\n",
       "   0.0006510048406198621,\n",
       "   0.001124231843277812],\n",
       "  'neutral_scores': [0.9979262351989746,\n",
       "   0.9984550476074219,\n",
       "   0.9978399276733398,\n",
       "   0.9974452257156372,\n",
       "   0.8848736882209778,\n",
       "   0.988490104675293,\n",
       "   0.9907208681106567,\n",
       "   0.9885304570198059],\n",
       "  'contradict_scores': [0.00015132708358578384,\n",
       "   0.001258120872080326,\n",
       "   0.0010625693248584867,\n",
       "   0.002410667948424816,\n",
       "   0.11323968321084976,\n",
       "   0.011377754621207714,\n",
       "   0.008628127165138721,\n",
       "   0.010345383547246456]}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T13:24:27.902797Z",
     "iopub.status.busy": "2025-09-14T13:24:27.902415Z",
     "iopub.status.idle": "2025-09-14T13:24:31.844501Z",
     "shell.execute_reply": "2025-09-14T13:24:31.839268Z",
     "shell.execute_reply.started": "2025-09-14T13:24:27.902765Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T13:24:31.847218Z",
     "iopub.status.busy": "2025-09-14T13:24:31.846963Z",
     "iopub.status.idle": "2025-09-14T13:24:32.075571Z",
     "shell.execute_reply": "2025-09-14T13:24:32.069754Z",
     "shell.execute_reply.started": "2025-09-14T13:24:31.847189Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!mkdir pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T13:24:34.298012Z",
     "iopub.status.busy": "2025-09-14T13:24:34.297612Z",
     "iopub.status.idle": "2025-09-14T13:24:34.314979Z",
     "shell.execute_reply": "2025-09-14T13:24:34.309827Z",
     "shell.execute_reply.started": "2025-09-14T13:24:34.297966Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import os\n",
    "os.system(\"pip install matplotlib\")\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "with open(\"data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "st.set_page_config(layout=\"wide\")\n",
    "st.title(\"LLM Response Evaluation Dashboard\")\n",
    "st.write(\"This dashboard evaluates and scores responses of LLM models, and checks it for semantic similarity, NLI-based entailment, adherence to specific instructions, coherency in responses and factual accuracy.✅\")\n",
    "\n",
    "st.header(\"Overall Trends\")\n",
    "plt.style.use('https://github.com/dhaitz/matplotlib-stylesheets/raw/master/pitayasmoothie-dark.mplstyle')\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12,8))\n",
    "# fig.suptitle(\"Overall Trends\", fontsize=16)\n",
    "n = list(range(1, len(data)+1))\n",
    "\n",
    "axs[0][0].plot(n, [d[\"semantic_score\"] for d in data.values()])\n",
    "axs[0][0].set_title(\"Semantic Scores\")\n",
    "axs[0][0].set_xticks(n)\n",
    "avg_semantic = sum([d[\"semantic_score\"] for d in data.values()]) / len(data)\n",
    "axs[0][0].axhline(y=avg_semantic, linestyle='--', label=f'Average Semantic Score: {avg_semantic:.3f}')\n",
    "axs[0][0].legend()\n",
    "\n",
    "axs[0][1].plot(n, [d[\"factual_accuracy_score\"] for d in data.values()])\n",
    "axs[0][1].set_title(\"Factual Accuracy\")\n",
    "axs[0][1].set_xticks(n)\n",
    "avg_factuality = sum([1 if d[\"factual_accuracy_score\"] else 0 for d in data.values()]) / len(data)\n",
    "axs[0][1].axhline(y=avg_factuality, linestyle='--', label=f'Average Factual Accuracy: {avg_factuality:.3f}')\n",
    "axs[0][1].legend()\n",
    "\n",
    "axs[1][0].plot(n, [d[\"normalized_perplexity\"] for d in data.values()])\n",
    "axs[1][0].set_title(\"Normalized Perplexity Score\")\n",
    "axs[1][0].set_xticks(n)\n",
    "avg_normalized_ppx = sum([d[\"normalized_perplexity\"] for d in data.values()]) / len(data)\n",
    "axs[1][0].axhline(y=avg_normalized_ppx, linestyle='--', label=f'Average Normalized Perplexity: {avg_normalized_ppx:.3f}')\n",
    "axs[1][0].legend()\n",
    "\n",
    "axs[1][1].plot(n, [d[\"grammar_score\"] for d in data.values()])\n",
    "axs[1][1].set_title(\"Grammar Score\")\n",
    "axs[1][1].set_xticks(n)\n",
    "avg_grammar_score = sum([d[\"grammar_score\"] for d in data.values()]) / len(data)\n",
    "axs[1][1].axhline(y=avg_grammar_score, linestyle='--', label=f'Average Grammar Score: {avg_grammar_score:.3f}')\n",
    "axs[1][1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "st.pyplot(fig)\n",
    "\n",
    "# st.metric(\"Factuality Rate\", f\"{avg_factuality*100:.2f}%\")\n",
    "\n",
    "st.header(\"Individual Responses\")\n",
    "\n",
    "for key in data.keys():\n",
    "    st.markdown(f\"[View Response {key}](Response?key={key})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T13:24:37.192581Z",
     "iopub.status.busy": "2025-09-14T13:24:37.192259Z",
     "iopub.status.idle": "2025-09-14T13:24:37.208807Z",
     "shell.execute_reply": "2025-09-14T13:24:37.202241Z",
     "shell.execute_reply.started": "2025-09-14T13:24:37.192555Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pages/2_Response.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pages/2_Response.py\n",
    "import streamlit as st\n",
    "import os\n",
    "os.system(\"pip install matplotlib numpy\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# key = st.session_state.get(\"key\", \"1\")\n",
    "key = st.query_params.key\n",
    "key = key\n",
    "\n",
    "with open(\"data.json\", \"r\") as f:\n",
    "    data = json.load(f)[key]\n",
    "\n",
    "st.header(\"Analysis Results\")\n",
    "st.subheader(\"1.1. Semantic Search Score\")\n",
    "\n",
    "st.metric(\"Semantic Score (0-1, closer to 1 is better)\", f\"{data['semantic_score']:.2f}\")\n",
    "st.info(\"Measures how semantically similar the response is to the prompt.\")\n",
    "\n",
    "st.subheader(\"1.2. Prompt-Response Entailment\")\n",
    "col_nli_1, col_nli_2, col_nli_3 = st.columns(3)\n",
    "col_nli_1.metric(\"Entailment\", f\"\"\"{data[\"entail_prob\"]:.2f}\"\"\")\n",
    "col_nli_2.metric(\"Neutrality\", f\"\"\"{data[\"neutral_prob\"]:.2f}\"\"\")\n",
    "col_nli_3.metric(\"Contradiction\", f\"\"\"{data[\"contradict_prob\"]:.2f}\"\"\")\n",
    "st.info(\"Measures the logical relationship between the prompt (premise) and the response (hypothesis).\")\n",
    "\n",
    "st.subheader(\"1.3. Sequential Sentence Coherence\")\n",
    "st.info(\"Measures the logical coherence between adjacent sentences. High entailment indicates a smooth, consistent flow.\")\n",
    "col_seq_1, col_seq_2, col_seq_3 = st.columns(3)\n",
    "col_seq_1.metric(\"Overall Entailment\", f\"\"\"{data[\"coherent_scores_overall_enc\"][0]:.2f}\"\"\")\n",
    "col_seq_2.metric(\"Overall Neutrality\", f\"\"\"{data[\"coherent_scores_overall_enc\"][1]:.2f}\"\"\")\n",
    "col_seq_3.metric(\"Overall Contradiction\", f\"\"\"{data[\"coherent_scores_overall_enc\"][2]:.2f}\"\"\")\n",
    "\n",
    "# Plotting the results\n",
    "sentences = data[\"agent_response\"].split('.')\n",
    "\n",
    "entail = data['entail_scores']\n",
    "neutral = data['neutral_scores']\n",
    "contradict = data['contradict_scores']\n",
    "\n",
    "pairs = [f\"S{i+1} -> S{i+2}\" for i in range(len(entail))]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Stacked bar chart\n",
    "\n",
    "ax1.bar(pairs, contradict, label=\"Contradiction\", color=\"red\")\n",
    "ax1.bar(pairs, neutral, bottom=contradict, label=\"Neutral\", color=\"gray\")\n",
    "ax1.bar(pairs, entail, bottom=[c + n for c, n in zip(contradict, neutral)], label=\"Entailment\", color=\"green\")\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.set_ylabel(\"Probability\")\n",
    "ax1.set_xlabel(\"Sentence Pair\")\n",
    "ax1.set_title(\"Entailment vs Neutral vs Contradiction (Sequential)\")\n",
    "ax1.legend()\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Grouped bar chart\n",
    "x = np.arange(len(pairs))\n",
    "width = 0.25\n",
    "ax2.bar(x - width, contradict, width, label=\"Contradiction\", color=\"red\")\n",
    "ax2.bar(x, neutral, width, label=\"Neutral\", color=\"gray\")\n",
    "ax2.bar(x + width, entail, width, label=\"Entailment\", color=\"green\")\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(pairs, rotation=45)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.set_ylabel(\"Probability\")\n",
    "ax2.set_xlabel(\"Sentence Pair\")\n",
    "ax2.set_title(\"Sequential Sentence Relations (NLI)\")\n",
    "ax2.legend()\n",
    "\n",
    "st.pyplot(fig)\n",
    "plt.clf()\n",
    "\n",
    "st.subheader(\"1.4. Text Fluency and Quality\")\n",
    "col_div1, col_div2 = st.columns(2)\n",
    "col_div1.metric(\"Unigram Diversity\", f\"\"\"{data[\"unigrams_diversity\"]:.2f}\"\"\")\n",
    "col_div2.metric(\"Bigram Diversity\", f\"\"\"{data[\"bigrams_diversity\"]:.2f}\"\"\")\n",
    "\n",
    "st.metric(\"Normalized Perplexity Score\", f\"\"\"{data[\"normalized_perplexity\"]:.2f}\"\"\")\n",
    "st.info(f\"\"\"Perplexity (raw): {data[\"raw_perplexity\"]:.2f}. Lower perplexity indicates higher fluency.\"\"\")\n",
    "\n",
    "st.metric(\"Grammar Quality Score\", f\"\"\"{data[\"grammar_score\"]:.2f}\"\"\")\n",
    "if data[\"grammar_errors\"]:\n",
    "    st.warning(\"Grammar Errors Found:\")\n",
    "    for error in data[\"grammar_errors\"]:\n",
    "        st.markdown(f\"- **Issue**: {error['message']} | **Found**: `{error['context']['text']}`\")\n",
    "else:\n",
    "    st.success(\"No grammar errors found by the checker.\")\n",
    "\n",
    "\n",
    "st.subheader(\"1.5. Instruction Adherence Check\")\n",
    "st.markdown(\"**Parsed Constraints:**\")\n",
    "st.json(data[\"parsed_constraints\"])\n",
    "\n",
    "eval_data = data[\"instruction_adherence\"]\n",
    "\n",
    "st.markdown(\"### LLM Evaluation Scores\")\n",
    "col_s1, col_s2, col_s3 = st.columns(3)\n",
    "col_s4, col_s5, col_final = st.columns(3)\n",
    "\n",
    "col_s1.metric(\"Quantity Score\", f\"{eval_data.get('quantity_score', 0):.2f}\")\n",
    "col_s2.metric(\"Format Score\", f\"{eval_data.get('format_score', 0):.2f}\")\n",
    "col_s3.metric(\"Length Score\", f\"{eval_data.get('length_score', 0):.2f}\")\n",
    "col_s4.metric(\"Style Score\", f\"{eval_data.get('style_score', 0):.2f}\")\n",
    "col_s5.metric(\"Do/Don't Score\", f\"{eval_data.get('do_dont_score', 0):.2f}\")\n",
    "col_final.metric(\"Final Score\", f\"{eval_data.get('final_score', 0):.2f}\")\n",
    "\n",
    "st.markdown(\"**Reasoning:**\")\n",
    "st.write(eval_data.get('reasoning', 'No reasoning provided.'))\n",
    "\n",
    "st.subheader(\"1.6. Factual Accuracy Check\")\n",
    "st.metric(\"Factual Accuracy Score\", f\"\"\"{data[\"factual_accuracy_score\"]:.2f}\"\"\")\n",
    "\n",
    "st.markdown(\"##### Extracted Claims:\")\n",
    "st.json(data['claims'])\n",
    "\n",
    "st.markdown(\"##### Evidences:\")\n",
    "st.json(data['evidences'])\n",
    "\n",
    "st.markdown(\"##### Factual Check Details:\")\n",
    "st.json(data[\"AI_as_judge_results\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T13:24:41.951161Z",
     "iopub.status.busy": "2025-09-14T13:24:41.950831Z",
     "iopub.status.idle": "2025-09-14T13:24:45.825505Z",
     "shell.execute_reply": "2025-09-14T13:24:45.820261Z",
     "shell.execute_reply.started": "2025-09-14T13:24:41.951135Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: json-repair in /usr/local/lib/python3.10/site-packages (0.50.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install json-repair\n",
    "import json_repair\n",
    "import json\n",
    "\n",
    "with open(\"data.json\", \"w\") as f:\n",
    "    json.dump(json_repair.loads(json.dumps(results)), f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T13:24:45.828058Z",
     "iopub.status.busy": "2025-09-14T13:24:45.827662Z",
     "iopub.status.idle": "2025-09-14T13:24:49.942996Z",
     "shell.execute_reply": "2025-09-14T13:24:49.936735Z",
     "shell.execute_reply.started": "2025-09-14T13:24:45.828026Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyngrok\n",
      "  Downloading pyngrok-7.3.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/site-packages (from pyngrok) (6.0.2)\n",
      "Installing collected packages: pyngrok\n",
      "Successfully installed pyngrok-7.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T13:24:49.945836Z",
     "iopub.status.busy": "2025-09-14T13:24:49.945542Z",
     "iopub.status.idle": "2025-09-14T13:24:52.034582Z",
     "shell.execute_reply": "2025-09-14T13:24:52.030869Z",
     "shell.execute_reply.started": "2025-09-14T13:24:49.945805Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NgrokTunnel: \"https://ec9ec71cee37.ngrok-free.app\" -> \"http://localhost:8501\"                       \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\n",
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8501\n",
      "  Network URL: http://172.19.2.2:8501\n",
      "  External URL: http://34.13.167.71:8501\n",
      "\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pyngrok import ngrok\n",
    "import os\n",
    "\n",
    "# Set the Streamlit port\n",
    "port = 8501\n",
    "ngrok.set_auth_token(\"32frCnc6yNene02xWYThb8jTgB6_2pNYAC6tYKi2W76FQ8Pf8\")\n",
    "\n",
    "# Start the tunnel\n",
    "public_url = ngrok.connect(port)\n",
    "print(public_url)\n",
    "\n",
    "# Run the app\n",
    "os.system(f\"streamlit run app.py --server.port {port} &\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 8266902,
     "sourceId": 13054878,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8267136,
     "sourceId": 13055210,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8267303,
     "sourceId": 13055475,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31091,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
